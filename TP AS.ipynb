{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apprentissage Supervisé\n",
    "HAMAT Abdoulaye, 2021446\n",
    "GLASS Philippe, 2007698\n",
    "\n",
    "## Feature Engineering et Classification\n",
    "Ce TP a pour but d'étudier différentes méthodes de classification supervisée sur des données présentant diverses structures : numériques, catégorielles et textuelles.\n",
    "\n",
    "### Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(threshold=1000000,suppress=True)\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score, precision_score, accuracy_score, roc_auc_score\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de donnée, Dimensions :  (4375, 13)\n",
      "Nombre d'entrée 0 :  1216  ( 27.79 %)\n",
      "Nombre d'entrée 1 :  3159  ( 72.21 %)\n",
      "\n",
      "Taille du jeu d'entrainement 2187 échantillons\n",
      "Taille du jeu de test :  2188 échantillons\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('./credit_scoring.csv', sep=';')\n",
    "X = data.iloc[:, 0:-1].values\n",
    "labels = data.iloc[:, 13].values\n",
    "nom_cols = data.columns\n",
    "\n",
    "n_zeros = np.histogram(labels, bins=2)[0][0]\n",
    "n_ones = np.histogram(labels, bins=2)[0][-1]\n",
    "\n",
    "print(\"Nombre de donnée, Dimensions : \",X.shape)\n",
    "print(\"Nombre d'entrée 0 : \", n_zeros, \" (\", round(n_zeros*100/len(labels), 2),\"%)\")\n",
    "print(\"Nombre d'entrée 1 : \", n_ones, \" (\", round(n_ones*100/len(labels), 2),\"%)\")\n",
    "print()\n",
    "X_train, X_test, labels_train, labels_test = train_test_split(X, labels, test_size = 0.5, random_state=1)\n",
    "print(\"Taille du jeu d'entrainement\", X_train.shape[0], \"échantillons\")\n",
    "print(\"Taille du jeu de test : \", X_test.shape[0],\"échantillons\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le jeu de données contient plus de 4000 entrées majoritairement de classe 1 (environ 70%). Nous avons donc divisé l'ensemble de données en un dataset de test, et un dataset d'entrainement.\n",
    "\n",
    "### Apprentissage et évaluation de modèles\n",
    "On commence par implémenter un arbre de décision de type CART sur les données d'entrainement, ainsi qu'un algorithme des K plus proches voisins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arbre CART\n",
      "\t Accuracy :  72.71 %\n",
      "\t Rappel :  79.92 %\n",
      "\t Précision :  81.94 %\n",
      "\t AUROC :  0.67\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def tree(X_train, labels_train, X_test, labels_test) :\n",
    "    \"\"\"Créer et évalue un arbre CART sur les données passées en argument\"\"\"\n",
    "    \n",
    "    clf = DecisionTreeClassifier(random_state=1) # Création arbre\n",
    "    clf.fit(X_train, labels_train)               # Entrainement\n",
    "\n",
    "    prediction = clf.predict(X_test) # Evaluation\n",
    "    correct = np.equal(prediction, labels_test).sum()\n",
    "    print(\"Arbre CART\")\n",
    "    print(\"\\t Accuracy : \", round(accuracy_score(labels_test, prediction)*100, 2),\"%\")\n",
    "    print(\"\\t Rappel : \", round(recall_score(labels_test, prediction)*100, 2), \"%\")\n",
    "    print(\"\\t Précision : \", round(precision_score(labels_test, prediction)*100, 2), \"%\")\n",
    "    print(\"\\t AUROC : \", round(roc_auc_score(labels_test, prediction), 2))\n",
    "tree(X_train, labels_train, X_test, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'algorithme CART permet de construire un arbre de classement binaire donnant une classe correcte dans 70%. Pour notre cas, on s'intéressera particulièrement à la précision :\n",
    "$$\\text{Précision} = \\frac{\\text{Nombre de clients correctement identifiés comme solvable}}{\\text{Nombre de clients identifiés comme solvable}}$$\n",
    "\n",
    "Si la précision est faible, cela indique que le classificateur considère des clients qui ne rembourseront pas leurs crédits comme solvables, ce qui qui est préjudiciable pour la banque. Une précision de 82% est assez satisfaisante. Nous allons faire la même expérience avec l'algorithme des K plus proches voisins (KNN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K plus proche voisins\n",
      "\t Accuracy :  72.49 %\n",
      "\t Rappel :  88.19 %\n",
      "\t Précision :  77.1 %\n",
      "\t AUROC :  0.6\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def knn(X_train, labels_train, X_test, labels_test):\n",
    "    \"\"\"Créer et évalue un KNN sur les données passées en argument\"\"\"\n",
    "    clustering = KNeighborsClassifier(n_neighbors=5) # Création du classifier\n",
    "    clustering.fit(X_train, labels_train)            # Entrainement\n",
    "\n",
    "    prediction = clustering.predict(X_test)  # Evaluation\n",
    "    correct = np.equal(prediction, labels_test).sum()\n",
    "    print(\"K plus proche voisins\")\n",
    "    print(\"\\t Accuracy : \", round(accuracy_score(labels_test, prediction)*100, 2),\"%\")\n",
    "    print(\"\\t Rappel : \", round(recall_score(labels_test, prediction)*100, 2), \"%\")\n",
    "    print(\"\\t Précision : \", round(precision_score(labels_test, prediction)*100, 2), \"%\")\n",
    "    print(\"\\t AUROC : \", round(roc_auc_score(labels_test, prediction), 2))\n",
    "knn(X_train, labels_train, X_test, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  <table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" id=\"sheet0\" class=\"sheet0 gridlines\">\n",
    "        <col class=\"col0\">\n",
    "        <col class=\"col1\">\n",
    "        <col class=\"col2\">\n",
    "        <tbody>\n",
    "          <tr class=\"row0\">\n",
    "            <td class=\"column0 style1 null\"></td>\n",
    "            <td class=\"column1 style1 s\">Class_0</td>\n",
    "            <td class=\"column2 style1 s\">Class_1</td>\n",
    "          </tr>\n",
    "          <tr class=\"row1\">\n",
    "            <td class=\"column0 style1 s\">Count</td>\n",
    "            <td class=\"column1 style2 s\">284315</td>\n",
    "              <td class=\"column2 style3 s\"><strong>492</strong></td>\n",
    "          </tr>\n",
    "          <tr class=\"row2\">\n",
    "            <td class=\"column0 style1 s\">mean</td>\n",
    "            <td class=\"column1 style1 s\">88.29</td>\n",
    "              <td class=\"column2 style4 s\"><strong>122.21</strong></td>\n",
    "          </tr>\n",
    "          <tr class=\"row3\">\n",
    "            <td class=\"column0 style1 s\">std</td>\n",
    "              <td class=\"column1 style5 s\"><strong>250.10</strong></td>\n",
    "            <td class=\"column2 style1 s\">256,68</td>\n",
    "          </tr>\n",
    "          <tr class=\"row4\">\n",
    "            <td class=\"column0 style1 s\">min</td>\n",
    "            <td class=\"column1 style1 s\">0</td>\n",
    "              <td class=\"column2 style3 s\"><strong>0</strong></td>\n",
    "          </tr>\n",
    "          <tr class=\"row4\">\n",
    "            <td class=\"column0 style1 s\">25%</td>\n",
    "            <td class=\"column1 style1 s\">5.65</td>\n",
    "              <td class=\"column2 style3 s\"><strong>1</strong></td>\n",
    "          </tr>\n",
    "          <tr class=\"row4\">\n",
    "            <td class=\"column0 style1 s\">50%</td>\n",
    "            <td class=\"column1 style1 s\">22</td>\n",
    "              <td class=\"column2 style3 s\"><strong>9.25</strong></td>\n",
    "          </tr>\n",
    "          <tr class=\"row4\">\n",
    "            <td class=\"column0 style1 s\">75%</td>\n",
    "            <td class=\"column1 style1 s\"> 77.05</td>\n",
    "              <td class=\"column2 style3 s\"><strong>105.89</strong></td>\n",
    "          </tr>\n",
    "          <tr class=\"row4\">\n",
    "            <td class=\"column0 style1 s\">max</td>\n",
    "            <td class=\"column1 style1 s\">25691.1</td>\n",
    "              <td class=\"column2 style3 s\"><strong>2125.87</strong></td>\n",
    "          </tr>\n",
    "        </tbody>\n",
    "    </table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arbre CART\n",
      "\t Accuracy :  72.71 %\n",
      "\t Rappel :  80.11 %\n",
      "\t Précision :  81.82 %\n",
      "\t AUROC :  0.67\n",
      "K plus proche voisins\n",
      "\t Accuracy :  75.27 %\n",
      "\t Rappel :  85.92 %\n",
      "\t Précision :  81.06 %\n",
      "\t AUROC :  0.67\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "# Calcul du scaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Rescaling des données\n",
    "X_train_norm = scaler.transform(X_train)\n",
    "X_test_norm = scaler.transform(X_test)\n",
    "\n",
    "# Evaluation des performances\n",
    "tree(X_train_norm, labels_train, X_test_norm, labels_test)\n",
    "knn(X_train_norm, labels_train, X_test_norm, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous constatons que la normalisation n'a pas beaucoup d'effets sur l'arbre, ce qui est logique étant donné sa structure. Cependant, elle semble améliorer légèrement les KNN qui dépendent plus de la taille des features : le calcul de la distance est fortement impacté par la variance des variables. Par conséquent, la normalisation des données permet de faire ressortir des informations masquées par les attributs trop étendus.\n",
    "\n",
    "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" id=\"sheet0\" class=\"sheet0 gridlines\">\n",
    "        <col class=\"col0\">\n",
    "        <col class=\"col1\">\n",
    "        <col class=\"col2\">\n",
    "        <tbody>\n",
    "          <tr class=\"row0\">\n",
    "            <td class=\"column0 style1 null\"></td>\n",
    "            <td class=\"column1 style1 s\">KNN sans normalisation</td>\n",
    "            <td class=\"column2 style1 s\">KNN avec normalisation</td>\n",
    "          </tr>\n",
    "          <tr class=\"row1\">\n",
    "            <td class=\"column0 style1 s\">Accuracy</td>\n",
    "            <td class=\"column1 style2 s\">72.5%</td>\n",
    "              <td class=\"column2 style3 s\"><strong>75.3%</strong></td>\n",
    "          </tr>\n",
    "          <tr class=\"row2\">\n",
    "            <td class=\"column0 style1 s\">précision</td>\n",
    "            <td class=\"column1 style1 s\">77.1%</td>\n",
    "              <td class=\"column2 style4 s\"><strong>81.0%</strong></td>\n",
    "          </tr>\n",
    "          <tr class=\"row3\">\n",
    "            <td class=\"column0 style1 s\">Rappel</td>\n",
    "              <td class=\"column1 style5 s\"><strong>88.2%</strong></td>\n",
    "            <td class=\"column2 style1 s\">85.9%</td>\n",
    "          </tr>\n",
    "          <tr class=\"row4\">\n",
    "            <td class=\"column0 style1 s\">Auroc</td>\n",
    "            <td class=\"column1 style1 s\">0.6</td>\n",
    "              <td class=\"column2 style3 s\"><strong>0.67</strong></td>\n",
    "          </tr>\n",
    "        </tbody>\n",
    "    </table>\n",
    "\n",
    "###  Création de nouvelles variables caractéristiques\n",
    "Nous allons utiliser l'ACP (analyse en composantes principales) pour mettre en évidence des combinaisons linéaires entre les colonnes et donc réduire le nombre d'axes. Cela pourrait éventuellement améliorer les performances des classifieurs :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arbre CART\n",
      "\t Accuracy :  73.63 %\n",
      "\t Rappel :  79.55 %\n",
      "\t Précision :  83.28 %\n",
      "\t AUROC :  0.69\n",
      "K plus proche voisins\n",
      "\t Accuracy :  75.64 %\n",
      "\t Rappel :  86.62 %\n",
      "\t Précision :  81.04 %\n",
      "\t AUROC :  0.67\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(3)\n",
    "X_train_pca = pca.fit_transform(X_train_norm)\n",
    "X_train_aug = np.concatenate((X_train_norm, X_train_pca), axis=1)\n",
    "\n",
    "X_test_pca = pca.transform(X_test_norm)\n",
    "X_test_aug = np.concatenate((X_test_norm, X_test_pca), axis=1)\n",
    "\n",
    "tree(X_train_aug, labels_train, X_test_aug, labels_test)\n",
    "knn(X_train_aug, labels_train, X_test_aug, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les résultats nous montrent que le PCA améliore les performances générales des deux algorithmes.\n",
    "\n",
    "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" id=\"sheet0\" class=\"sheet0 gridlines\">\n",
    "        <col class=\"col0\">\n",
    "        <col class=\"col1\">\n",
    "        <col class=\"col2\">\n",
    "        <col class=\"col3\">\n",
    "        <col class=\"col4\">\n",
    "        <tbody>\n",
    "          <tr class=\"row0\">\n",
    "            <td class=\"column0 style1 null\"></td>\n",
    "            <td class=\"column1 style1 s\">Accuracy</td>\n",
    "            <td class=\"column2 style1 s\">Rappel</td>\n",
    "            <td class=\"column3 style1 s\">Précision</td>\n",
    "            <td class=\"column4 style1 s\">Auroc</td>\n",
    "          </tr>\n",
    "          <tr class=\"row1\">\n",
    "            <td class=\"column0 style1 s\">CART sans PCA</td>\n",
    "            <td class=\"column1 style2 s\">72.5%</td>\n",
    "              <td class=\"column2 style4 s\"><strong>80.0%</strong></td>\n",
    "            <td class=\"column3 style1 s\">77.1%</td>\n",
    "            <td class=\"column4 style1 s\">0.67</td>\n",
    "          </tr>\n",
    "          <tr class=\"row2\">\n",
    "            <td class=\"column0 style1 s\">CART avec PCA</td>\n",
    "              <td class=\"column1 style3 s\"><strong>73.6%</strong></td>\n",
    "            <td class=\"column2 style5 s\">79.5%</td>\n",
    "              <td class=\"column3 style3 s\"><strong>83.3%</strong></td>\n",
    "              <td class=\"column4 style3 s\"><strong>0.69</strong></td>\n",
    "          </tr>\n",
    "          <tr class=\"row3\">\n",
    "            <td class=\"column0 style1 s\">KNN sans PCA</td>\n",
    "            <td class=\"column1 style6 s\">72.5%</td>\n",
    "              <td class=\"column2 style3 s\"><strong>88.2%</strong></td>\n",
    "            <td class=\"column3 style1 s\">77.1%</td>\n",
    "            <td class=\"column4 style1 s\">0.6</td>\n",
    "          </tr>\n",
    "          <tr class=\"row4\">\n",
    "            <td class=\"column0 style1 s\">KNN avec PCA</td>\n",
    "              <td class=\"column1 style3 s\"><strong>75.6%</strong></td>\n",
    "            <td class=\"column2 style7 s\">86.6%</td>\n",
    "              <td class=\"column3 style4 s\"><strong>81.0%</strong></td>\n",
    "              <td class=\"column4 style3 s\"><strong>0.67</strong></td>\n",
    "          </tr>\n",
    "        </tbody>\n",
    "</table>\n",
    "\n",
    "### Sélection de variables\n",
    "L'utilisation d'un Random-Forest permet d'identifier les variables les plus pertinentes vis-à-vis de la classification. On va donc étudier l'intérêt de chaque feature pour réduire l'impureté de chaque noeud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_train_norm, labels_train)\n",
    "\n",
    "importances=clf.feature_importances_\n",
    "\n",
    "std = np.std([tree.feature_importances_ for tree in clf.estimators_],axis=0)\n",
    "sorted_idx = np.argsort(importances)[::-1]\n",
    "features =nom_cols\n",
    "\n",
    "padding = np.arange(X_train_norm.size/len(X_train_norm)) + 0.5\n",
    "plt.barh(padding, importances[sorted_idx],xerr=std[sorted_idx], align='center')\n",
    "plt.yticks(padding, features[sorted_idx])\n",
    "plt.xlabel(\"Relative Importance\")\n",
    "plt.title(\"Variable Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les variables les plus importantes pour la classification sont le revenu et l'ancienneté alors que le mariage et le fait de posséder une maison influence peu. On va maintenant chercher à déduire le nombre de features minimum pour classer au mieux les données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from time import time_ns\n",
    "\n",
    "KNN=KNeighborsClassifier(n_neighbors=5)\n",
    "scores=np.zeros(X_train_norm.shape[1]+1)\n",
    "for f in np.arange(0, X_train_norm.shape[1]+1):\n",
    "    X1_f = X_train_norm[:,sorted_idx[:f+1]]\n",
    "    X2_f = X_test_norm[:,sorted_idx[:f+1]]\n",
    "    KNN.fit(X1_f,labels_train)\n",
    "    YKNN=KNN.predict(X2_f)\n",
    "    scores[f]=np.round(accuracy_score(labels_test,YKNN),3)\n",
    "\n",
    "plt.plot(scores)\n",
    "plt.xlabel(\"Nombre de Variables\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Evolution de l'accuracy en fonction des variables\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On se limite aux 7 premières variables (premier décrochage da la courbe) : *Income*, *Seniority*, *Price*, *Amount*, *Age*, *Assets* et *Expense*. On peut procéder de même avec la classification en arbre, ce qui donne les résultats ci-dessous :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tree=DecisionTreeClassifier()\n",
    "scores=np.zeros(X_train_norm.shape[1]+1)\n",
    "for f in np.arange(0, X_train_norm.shape[1]+1):\n",
    "    X1_f = X_train_norm[:,sorted_idx[:f+1]]\n",
    "    X2_f = X_test_norm[:,sorted_idx[:f+1]]\n",
    "    tree.fit(X1_f,labels_train)\n",
    "    Ytree=tree.predict(X2_f)\n",
    "    scores[f]=np.round(accuracy_score(labels_test,Ytree),3)\n",
    "\n",
    "plt.plot(scores)\n",
    "plt.xlabel(\"Nombre de Variables\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Evolution de l'accuracy en fonction des variables\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette étude nous a permis d'adapter le nombre de variables sans sacrifier l'accuracy. Cela peut être intéressant si le nombre de *features* est trop grand et que l'on souhaite réduire le temps de calcul sans impacter les performances.\n",
    "\n",
    "### Paramétrage des classifieurs\n",
    "On doit maintenant régler les paramètres de chacun des algorithmes pour obtenir les meilleures performances possibles. Pour cela, on va utiliser la fonctionnalité de SKLearn qui permet d'explorer rapidement différents paramètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Best :  [{'max_depth': 4, 'max_features': 6, 'min_samples_leaf': 2}, 77.33]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "parameters = {\"min_samples_leaf\" : [2, 5, 10],\n",
    "             'max_depth' : [None, 2, 4, 6],\n",
    "             \"max_features\" : [None, 2, 4, 6, 8]}\n",
    "scoring = {'AUC': 'roc_auc','Accuracy': make_scorer(accuracy_score)}\n",
    "\n",
    "gs = GridSearchCV(DecisionTreeClassifier(random_state=1),\n",
    "                  param_grid=parameters,\n",
    "                  scoring=scoring, refit='AUC', return_train_score=True)\n",
    "\n",
    "gs.fit(X, labels)\n",
    "results = gs.cv_results_\n",
    "best = [results[\"params\"][0], round(results['mean_test_Accuracy'][0]*100, 2)]\n",
    "for i in range(len(results['mean_test_Accuracy'])):\n",
    "    # print(results[\"params\"][i], \" : \", round(results['mean_test_Accuracy'][i]*100, 2), \"%\")\n",
    "    if round(results['mean_test_Accuracy'][i]*100, 2) > best[1]:\n",
    "        best = [results[\"params\"][i], round(results['mean_test_Accuracy'][i]*100, 2)]\n",
    "print(\"\\n Best : \", best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'algorithme ci-dessus nous donne les meilleurs paramètres pour la classification en arbres. Il affiche seulement le meilleur résultat, mais en analysant les performances détaillées : le paramètre min_samples_leaf n'influe que très peu sur la précision, contrairement au paramètre max_depth qui influe beaucoup plus.\n",
    "On effectue la même opération avec l'algorithme des KNN :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Best:  [{'n_neighbors': 17, 'p': 1}, 73.78]\n"
     ]
    }
   ],
   "source": [
    "parameters = {'n_neighbors':range(5, 20, 2),\n",
    "             \"p\" : [1, 2],}\n",
    "scoring = {'AUC': 'roc_auc','Accuracy': make_scorer(accuracy_score)}\n",
    "\n",
    "gs = GridSearchCV(KNeighborsClassifier(),\n",
    "                  param_grid=parameters,\n",
    "                  scoring=scoring, refit='AUC', return_train_score=True)\n",
    "\n",
    "gs.fit(X, labels)\n",
    "results = gs.cv_results_\n",
    "\n",
    "best = [results[\"params\"][0], round(results['mean_test_Accuracy'][0]*100, 2)]\n",
    "for i in range(len(results['mean_test_Accuracy'])):\n",
    "    # print(results[\"params\"][i], \" : \", round(results['mean_test_Accuracy'][i]*100, 2), \"%\")\n",
    "    if round(results['mean_test_Accuracy'][i]*100, 2) > best[1]:\n",
    "        best = [results[\"params\"][i], round(results['mean_test_Accuracy'][i]*100, 2)]\n",
    "print(\"\\n Best: \", best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous constatons sans surprise que la précision est meilleure lorsque le nombre de voisins augmente mais nous constatons également que la distance de Manhattan donne un léger avantage par rapport à la norme euclidienne. \n",
    "### Pipeline\n",
    "L'ensemble de la procédure a été stockée dans un pipeline puis enregistrée dans un fichier *save_pip.p*. Cela permet de recharger rapidement le classifieur sans avoir à ré-entrainer le modèle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  77.51 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "import pickle\n",
    "scaler = StandardScaler()\n",
    "pca = PCA(3)\n",
    "\n",
    "sub_pip = FeatureUnion([(\"pca\", Pipeline(([\"scale\", scaler], [\"pca\", pca]))), (\"scaler\", scaler)])\n",
    "\n",
    "pipeline = Pipeline([('ss',StandardScaler()),\n",
    "                    ('classifieur',KNeighborsClassifier(n_neighbors=17))\n",
    "              ])\n",
    "pipeline.fit(X_train, labels_train)\n",
    "pickle.dump(pipeline, open( \"save_pip.p\", \"wb\" ))\n",
    "pipeline = pickle.load(open(\"save_pip.p\", \"rb\"))\n",
    "prediction = pipeline.predict(X_test)\n",
    "print(\"Accuracy : \", round(accuracy_score(labels_test, prediction)*100, 2),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le code ci-dessus permet  d'enregistrer puis de recharger un modèle entrainé.\n",
    "### Comparaison de plusieurs algorithmes\n",
    "Pour comparer les différents algorithmes, nous utilisons plusieurs métriques, : l'accuracy, l'aire sur la courbe AUC qui doit être proche de 1, le temps de calcul nécessaire et la précision. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NBayes ( 1.4 ms)\n",
      "\t Accuracy : 77.0 +/- 2.2 %\n",
      "\t AUROC : 0.79 +/- 0.03\n",
      "\t Précision : 83.0 +/- 1.3 %\n",
      "Tree ( 3.0 ms)\n",
      "\t Accuracy : 77.0 +/- 1.2 %\n",
      "\t AUROC : 0.77 +/- 0.01\n",
      "\t Précision : 81.0 +/- 1.4 %\n",
      "MLP ( 462.9 ms)\n",
      "\t Accuracy : 70.0 +/- 6.5 %\n",
      "\t AUROC : 0.71 +/- 0.05\n",
      "\t Précision : 80.0 +/- 4.4 %\n",
      "KNN ( 12.6 ms)\n",
      "\t Accuracy : 74.0 +/- 1.7 %\n",
      "\t AUROC : 0.69 +/- 0.03\n",
      "\t Précision : 76.0 +/- 1.3 %\n",
      "Bagging ( 507.2 ms)\n",
      "\t Accuracy : 77.0 +/- 1.5 %\n",
      "\t AUROC : 0.82 +/- 0.02\n",
      "\t Précision : 82.0 +/- 0.5 %\n",
      "Adaboost ( 137.2 ms)\n",
      "\t Accuracy : 79.0 +/- 1.6 %\n",
      "\t AUROC : 0.83 +/- 0.02\n",
      "\t Précision : 82.0 +/- 1.2 %\n",
      "Randomforest ( 185.3 ms)\n",
      "\t Accuracy : 79.0 +/- 1.9 %\n",
      "\t AUROC : 0.82 +/- 0.02\n",
      "\t Précision : 82.0 +/- 0.8 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate , KFold\n",
    "\n",
    "\n",
    "def run_classifiers(clfs, X, Y):\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "    kf2 = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    for i in clfs:\n",
    "        clf = clfs[i]\n",
    "        cv = cross_validate(clf, X, Y, cv=kf, scoring=scoring)\n",
    "        cv2 = cross_validate(clf, X, Y, cv=kf2, scoring={\"Precision\" : make_scorer(precision_score)})\n",
    "        cv_time = cv['fit_time']\n",
    "        cv_acc = cv['test_Accuracy']\n",
    "        cv_auc = cv[\"test_AUC\"]\n",
    "        cv_prec = cv2[\"test_Precision\"]\n",
    "        print(i, \"(\", round(np.mean(cv_time)*1000, 1), \"ms)\")\n",
    "        print(\"\\t Accuracy :\", round(np.mean(cv_acc),2)*100,\"+/-\", round(np.std(cv_acc)*100,1),\"%\")\n",
    "        print(\"\\t AUROC :\", round(np.mean(cv_auc),2),\"+/-\", round(np.std(cv_auc),2))\n",
    "        print(\"\\t Précision :\", round(np.mean(cv_prec),2)*100,\"+/-\", round(np.std(cv_prec)*100,1),\"%\")\n",
    "\n",
    "\n",
    "clfs = {\"NBayes\" : GaussianNB(),\n",
    "\"Tree\" : DecisionTreeClassifier(max_depth=4, max_features=8, min_samples_leaf=10),\n",
    "\"MLP\" : MLPClassifier([20, 10]),\n",
    "\"KNN\" : KNeighborsClassifier(n_neighbors=19, p=1),\n",
    "\"Bagging\" : BaggingClassifier(n_estimators=50),\n",
    "\"Adaboost\" : AdaBoostClassifier(n_estimators=50),\n",
    "\"Randomforest\" : RandomForestClassifier(n_estimators=50)}\n",
    "\n",
    "run_classifiers(clfs, X, labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selon les scores obtenus, les algorithmes les plus performants sont Naive Bayes, Adaboost**, RandomForest** et Bagging. Naive Bayes se distingue hautement grâce à sa rapidité et ses excellentes performances. Le perceptron multicouches donne une accuracy plus faible que les autres, mais possède une meilleure précision. \n",
    "    <table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" id=\"sheet0\" class=\"sheet0 gridlines\">\n",
    "        <col class=\"col0\">\n",
    "        <col class=\"col1\">\n",
    "        <col class=\"col2\">\n",
    "        <col class=\"col3\">\n",
    "        <col class=\"col4\">\n",
    "        <tbody>\n",
    "          <tr class=\"row0\">\n",
    "            <td class=\"column0 style1 null\"></td>\n",
    "            <td class=\"column1 style1 s\">Accuracy</td>\n",
    "            <td class=\"column2 style1 s\">Précision</td>\n",
    "            <td class=\"column3 style1 s\">Auroc</td>\n",
    "            <td class=\"column4 style1 s\">Time</td>\n",
    "          </tr>\n",
    "          <tr class=\"row1\">\n",
    "            <td class=\"column0 style1 s\">Nbayes</td>\n",
    "            <td class=\"column1 style2 s\">77.0%</td>\n",
    "            <td class=\"column2 style6 s\">83.0%</td>\n",
    "            <td class=\"column3 style1 s\">0.79</td>\n",
    "            <td class=\"column4 style1 s\">1.5ms</td>\n",
    "          </tr>\n",
    "          <tr class=\"row2\">\n",
    "            <td class=\"column0 style1 s\">CART</td>\n",
    "            <td class=\"column1 style2 s\">76.0%</td>\n",
    "            <td class=\"column2 style6 s\">79.0%</td>\n",
    "            <td class=\"column3 style7 s\">0.77</td>\n",
    "              <td class=\"column4 style3 s\"><strong>3.6ms</strong></td>\n",
    "          </tr>\n",
    "          <tr class=\"row3\">\n",
    "            <td class=\"column0 style1 s\">MLP</td>\n",
    "            <td class=\"column1 style2 s\">72.0%</td>\n",
    "              <td class=\"column2 style4 s\"><strong>80.0%</strong></td>\n",
    "            <td class=\"column3 style1 s\">0.7</td>\n",
    "            <td class=\"column4 style1 s\"> 754.8 ms</td>\n",
    "          </tr>\n",
    "          <tr class=\"row4\">\n",
    "            <td class=\"column0 style1 s\">KNN</td>\n",
    "            <td class=\"column1 style2 s\">74.0%</td>\n",
    "            <td class=\"column2 style6 s\">76.0%</td>\n",
    "            <td class=\"column3 style6 s\">0.69</td>\n",
    "            <td class=\"column4 style7 s\">13.9 ms</td>\n",
    "          </tr>\n",
    "          <tr class=\"row5\">\n",
    "            <td class=\"column0 style8 s\">Bagging</td>\n",
    "            <td class=\"column1 style2 s\">77.0%</td>\n",
    "            <td class=\"column2 style4 s\"><strong>83.0%</strong></td>\n",
    "            <td class=\"column3 style8 s\">0.82</td>\n",
    "            <td class=\"column4 style8 s\">583.3 ms</td>\n",
    "          </tr>\n",
    "          <tr class=\"row6\">\n",
    "            <td class=\"column0 style8 s\">Adaboost</td>\n",
    "            <td class=\"column1 style5 s\"><strong>79.0%</strong></td>\n",
    "             <td class=\"column2 style4 s\"><strong>82.0%</strong></td>\n",
    "              <td class=\"column3 style9 s\"><strong>0.83</strong></td>\n",
    "            <td class=\"column4 style10 s\">167.8 ms</td>\n",
    "          </tr>\n",
    "          <tr class=\"row7\">\n",
    "            <td class=\"column0 style8 s\">RandomForest</td>\n",
    "            <td class=\"column1 style2 s\">78.0%</td>\n",
    "             <td class=\"column2 style4 s\"><strong>82.0%</strong></td>\n",
    "            <td class=\"column3 style8 s\">0.82</td>\n",
    "            <td class=\"column4 style8 s\">218.4 ms</td>\n",
    "          </tr>\n",
    "        </tbody>\n",
    "    </table>\n",
    "\n",
    "## Apprentissage supervisé : Données hétérogènes\n",
    "Dans cette partie, nous traitons un jeu des données hétérogènes qui contiennent à la fois des données numériques et des données catégorielles.\n",
    "### Chargement des données\n",
    "Nous procédons comme suit :\n",
    "- Séparation des données numériques des données catégorielles\n",
    "- Remplacer les données manquantes par des \"nan\"\n",
    "- Transformation des labels en booléens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de l'échantillon :  (665, 6)\n",
      "Nombre d'entrée 0 :  367  ( 55.19 %)\n",
      "Nombre d'entrée 1 :  298  ( 44.81 %)\n",
      "Nombre de lignes avec des données manquantes :  22\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('./credit.data', sep=None)\n",
    "data_array = data.values\n",
    "X = data_array[:, 0:-1]\n",
    "Y = data_array[:, -1]\n",
    "\n",
    "\n",
    "# Isolation des colonnes numériques\n",
    "col_cat = [0,3,4,5,6,8,9,11,12]\n",
    "col_num = [1, 2, 7, 10, 13, 14]\n",
    "\n",
    "X_numeric = X[:, col_num]\n",
    "X_numeric[X_numeric==\"?\"] = np.nan\n",
    "X_numeric = X_numeric.astype(np.float)\n",
    "\n",
    "nan_lines = np.isnan(X_numeric).any(axis=1)\n",
    "X_numeric = X_numeric[~nan_lines]\n",
    "\n",
    "# Binarisation\n",
    "Y = np.where(Y=='+', 1, Y)\n",
    "Y = np.where(Y=='-', 0, Y)\n",
    "Y = Y.astype(np.int)\n",
    "Y_numeric = Y[~nan_lines]\n",
    "print(\"Taille de l'échantillon : \", X_numeric.shape)\n",
    "\n",
    "n_zeros = np.histogram(Y_numeric)[0][0]\n",
    "n_ones = np.histogram(Y_numeric)[0][-1]\n",
    "print(\"Nombre d'entrée 0 : \", n_zeros, \" (\", round(n_zeros*100/len(Y_numeric), 2),\"%)\")\n",
    "print(\"Nombre d'entrée 1 : \", n_ones, \" (\", round(n_ones*100/len(Y_numeric), 2),\"%)\")\n",
    "print(\"Nombre de lignes avec des données manquantes : \", nan_lines.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'ensemble comporte 22 lignes avec des données manquantes et l'échantillon comporte 665 entrées réparties équitablement entre les deux classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test des algorithmes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On commence par tester les algorithmes de classification sur l'ensemble des données numériques :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NBayes ( 0.2 ms)\n",
      "\t Accuracy : 71.0 +/- 5.8 %\n",
      "\t AUROC : 0.79 +/- 0.06\n",
      "\t Précision : 85.0 +/- 8.9 %\n",
      "Tree ( 0.1 ms)\n",
      "\t Accuracy : 70.0 +/- 4.5 %\n",
      "\t AUROC : 0.7 +/- 0.04\n",
      "\t Précision : 67.0 +/- 6.5 %\n",
      "MLP ( 280.8 ms)\n",
      "\t Accuracy : 57.99999999999999 +/- 10.4 %\n",
      "\t AUROC : 0.62 +/- 0.11\n",
      "\t Précision : 50.0 +/- 26.6 %\n",
      "KNN ( 1.6 ms)\n",
      "\t Accuracy : 68.0 +/- 4.6 %\n",
      "\t AUROC : 0.75 +/- 0.04\n",
      "\t Précision : 73.0 +/- 4.7 %\n",
      "Bagging ( 91.0 ms)\n",
      "\t Accuracy : 76.0 +/- 5.6 %\n",
      "\t AUROC : 0.82 +/- 0.05\n",
      "\t Précision : 81.0 +/- 3.7 %\n",
      "Adaboost ( 55.9 ms)\n",
      "\t Accuracy : 79.0 +/- 5.3 %\n",
      "\t AUROC : 0.85 +/- 0.05\n",
      "\t Précision : 79.0 +/- 4.2 %\n",
      "Randomforest ( 61.3 ms)\n",
      "\t Accuracy : 78.0 +/- 6.4 %\n",
      "\t AUROC : 0.85 +/- 0.06\n",
      "\t Précision : 79.0 +/- 4.3 %\n"
     ]
    }
   ],
   "source": [
    "clfs = {\"NBayes\" : GaussianNB(),\n",
    "\"Tree\" : DecisionTreeClassifier(),\n",
    "\"MLP\" : MLPClassifier([6, 20, 10, 2]),\n",
    "\"KNN\" : KNeighborsClassifier(n_neighbors=19, p=1),\n",
    "\"Bagging\" : BaggingClassifier(n_estimators=50),\n",
    "\"Adaboost\" : AdaBoostClassifier(n_estimators=50),\n",
    "\"Randomforest\" : RandomForestClassifier(n_estimators=50)\n",
    "}\n",
    "run_classifiers(clfs, X_numeric, Y_numeric)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les algorithmes les plus performants sont Adaboost** et Naive Bayes qui donnent une AUROC relativement proche de 1 et une précision bien supérieure aux autres. Les performances du MLP sont étonnantes car à la fois très faibles mais présentant une grande incertitude. On va donc s'intéresser à faire évoluer l'architecture du MLP afin d'obtenir de meilleures performances. Cependant, le temps d'entrainement est trop long pour le rendre intéressant vis-à-vis des autres candidats.\n",
    "\n",
    "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" id=\"sheet0\" class=\"sheet0 gridlines\">\n",
    "        <colgroup><col class=\"col0\">\n",
    "        <col class=\"col1\">\n",
    "        <col class=\"col2\">\n",
    "        <col class=\"col3\">\n",
    "        <col class=\"col4\">\n",
    "        </colgroup><tbody>\n",
    "          <tr class=\"row0\">\n",
    "            <td class=\"column0 style1 null\"></td>\n",
    "            <td class=\"column1 style1 s\">Accuracy</td>\n",
    "            <td class=\"column2 style1 s\">Précision</td>\n",
    "            <td class=\"column3 style1 s\">Auroc</td>\n",
    "            <td class=\"column4 style1 s\">Time</td>\n",
    "          </tr>\n",
    "          <tr class=\"row1\">\n",
    "            <td class=\"column0 style1 s\">Nbayes</td>\n",
    "            <td class=\"column1 style2 s\">71.0%</td>\n",
    "              <td class=\"column2 style4 s\"><strong>85.0%</strong></td>\n",
    "            <td class=\"column3 style1 s\">0.79</td>\n",
    "            <td class=\"column4 style3 s\"><strong>0.6ms</strong></td>\n",
    "          </tr>\n",
    "          <tr class=\"row2\">\n",
    "            <td class=\"column0 style1 s\">CART</td>\n",
    "            <td class=\"column1 style2 s\">71.0%</td>\n",
    "            <td class=\"column2 style6 s\">65.0%</td>\n",
    "            <td class=\"column3 style7 s\">0.71</td>\n",
    "            <td class=\"column4 style7 s\">1.3ms</td>\n",
    "          </tr>\n",
    "          <tr class=\"row3\">\n",
    "            <td class=\"column0 style1 s\">MLP</td>\n",
    "            <td class=\"column1 style2 s\">54.0%</td>\n",
    "            <td class=\"column2 style6 s\">33.0%</td>\n",
    "            <td class=\"column3 style1 s\">0.57</td>\n",
    "            <td class=\"column4 style1 s\">211.4ms</td>\n",
    "          </tr>\n",
    "          <tr class=\"row4\">\n",
    "            <td class=\"column0 style1 s\">KNN</td>\n",
    "            <td class=\"column1 style2 s\">68.0%</td>\n",
    "            <td class=\"column2 style6 s\">73.0%</td>\n",
    "            <td class=\"column3 style6 s\">0.75</td>\n",
    "            <td class=\"column4 style3 s\"><strong>0.5ms</strong></td>\n",
    "          </tr>\n",
    "          <tr class=\"row5\">\n",
    "            <td class=\"column0 style8 s\">Bagging</td>\n",
    "            <td class=\"column1 style2 s\">77.0%</td>\n",
    "            <td class=\"column2 style6 s\">77.0%</td>\n",
    "            <td class=\"column3 style8 s\">0.83</td>\n",
    "            <td class=\"column4 style8 s\">62.0ms</td>\n",
    "          </tr>\n",
    "          <tr class=\"row6\">\n",
    "            <td class=\"column0 style8 s\">Adaboost</td>\n",
    "            <td class=\"column1 style5 s\"><strong>79.0%</strong></td>\n",
    "            <td class=\"column2 style6 s\">79.0%</td>\n",
    "            <td class=\"column3 style9 s\"><strong>0.85</strong></td>\n",
    "            <td class=\"column4 style10 s\">40.8ms</td>\n",
    "          </tr>\n",
    "          <tr class=\"row7\">\n",
    "            <td class=\"column0 style8 s\">RandomForest</td>\n",
    "            <td class=\"column1 style2 s\">77.0%</td>\n",
    "            <td class=\"column2 style6 s\">80.0%</td>\n",
    "            <td class=\"column3 style8 s\">0.84</td>\n",
    "            <td class=\"column4 style8 s\">37.6ms</td>\n",
    "          </tr>\n",
    "        </tbody>\n",
    "    </table>\n",
    "\n",
    "\n",
    "### Normalisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NBayes ( 0.7 ms)\n",
      "\t Accuracy : 71.0 +/- 5.8 %\n",
      "\t AUROC : 0.79 +/- 0.06\n",
      "\t Précision : 85.0 +/- 8.9 %\n",
      "Tree ( 1.7 ms)\n",
      "\t Accuracy : 70.0 +/- 4.9 %\n",
      "\t AUROC : 0.7 +/- 0.04\n",
      "\t Précision : 66.0 +/- 4.1 %\n",
      "MLP ( 328.8 ms)\n",
      "\t Accuracy : 74.0 +/- 9.0 %\n",
      "\t AUROC : 0.78 +/- 0.11\n",
      "\t Précision : 49.0 +/- 39.9 %\n",
      "KNN ( 0.0 ms)\n",
      "\t Accuracy : 74.0 +/- 6.9 %\n",
      "\t AUROC : 0.82 +/- 0.04\n",
      "\t Précision : 87.0 +/- 3.6 %\n",
      "Bagging ( 93.2 ms)\n",
      "\t Accuracy : 77.0 +/- 5.3 %\n",
      "\t AUROC : 0.83 +/- 0.05\n",
      "\t Précision : 77.0 +/- 3.8 %\n",
      "Adaboost ( 52.2 ms)\n",
      "\t Accuracy : 79.0 +/- 5.3 %\n",
      "\t AUROC : 0.85 +/- 0.05\n",
      "\t Précision : 79.0 +/- 4.2 %\n",
      "Randomforest ( 60.4 ms)\n",
      "\t Accuracy : 78.0 +/- 5.8 %\n",
      "\t AUROC : 0.84 +/- 0.05\n",
      "\t Précision : 77.0 +/- 4.6 %\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "Xn_scaled = scaler.fit_transform(X_numeric)\n",
    "run_classifiers(clfs, Xn_scaled, Y_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La normalisation semble augmenter les performances des classifieurs \"k plus proches voisins\" et Perceptron multicouches dont les scores se sont stabilisés. Elle n'a pas eu d'impact significatif sur l'arbre CART, car ce dernier n'est pas influencé par la plage de valeurs de chaque attribut. C'est également le cas pour les classifieurs Bagging, Adaboost et Random-Forest (et ce pour les mêmes raisons).\n",
    "\n",
    " <table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" id=\"sheet0\" class=\"sheet0 gridlines\">\n",
    "        <col class=\"col0\">\n",
    "        <col class=\"col1\">\n",
    "        <col class=\"col2\">\n",
    "        <col class=\"col3\">\n",
    "        <col class=\"col4\">\n",
    "        <tbody>\n",
    "          <tr class=\"row0\">\n",
    "            <td class=\"column0 style1 null\"></td>\n",
    "            <td class=\"column1 style1 s\">Accuracy</td>\n",
    "            <td class=\"column2 style1 s\">Précision</td>\n",
    "            <td class=\"column3 style1 s\">Auroc</td>\n",
    "            <td class=\"column4 style11 null\"></td>\n",
    "          </tr>\n",
    "          <tr class=\"row1\">\n",
    "            <td class=\"column0 style1 s\">Nbayes</td>\n",
    "            <td class=\"column1 style2 s\">71.0%</td>\n",
    "            <td class=\"column2 style6 s\">85.0%</td>\n",
    "            <td class=\"column3 style1 s\">0.79</td>\n",
    "            <td class=\"column4 style12 null\"></td>\n",
    "          </tr>\n",
    "          <tr class=\"row2\">\n",
    "            <td class=\"column0 style1 s\">CART</td>\n",
    "            <td class=\"column1 style2 s\">71.0%</td>\n",
    "            <td class=\"column2 style6 s\">66.0%</td>\n",
    "            <td class=\"column3 style8 s\">0.71</td>\n",
    "            <td class=\"column4 style13 null\"></td>\n",
    "          </tr>\n",
    "          <tr class=\"row3\">\n",
    "            <td class=\"column0 style1 s\"><strong>MLP</strong></td>\n",
    "            <td class=\"column1 style5 s\"><strong>73.0%</strong></td>\n",
    "            <td class=\"column2 style4 s\"><strong>70.0%</strong></td>\n",
    "            <td class=\"column3 style3 s\"><strong>0.78</strong></td>\n",
    "            <td class=\"column4 style11 null\"></td>\n",
    "          </tr>\n",
    "          <tr class=\"row4\">\n",
    "            <td class=\"column0 style1 s\"><strong>KNN</strong></td>\n",
    "            <td class=\"column1 style5 s\"><strong>74.0%</strong></td>\n",
    "            <td class=\"column2 style4 s\"><strong>87.0%</strong></td>\n",
    "            <td class=\"column3 style4 s\"><strong>0.82</strong></td>\n",
    "            <td class=\"column4 style12 null\"></td>\n",
    "          </tr>\n",
    "          <tr class=\"row5\">\n",
    "            <td class=\"column0 style9 s\">Bagging</td>\n",
    "            <td class=\"column1 style2 s\">77.0%</td>\n",
    "            <td class=\"column2 style6 s\">77.0%</td>\n",
    "            <td class=\"column3 style9 s\">0.83</td>\n",
    "            <td class=\"column4 style14 null\"></td>\n",
    "          </tr>\n",
    "          <tr class=\"row6\">\n",
    "            <td class=\"column0 style9 s\">Adaboost</td>\n",
    "            <td class=\"column1 style7 s\">79.0%</td>\n",
    "            <td class=\"column2 style6 s\">79.0%</td>\n",
    "            <td class=\"column3 style10 s\">0.85</td>\n",
    "            <td class=\"column4 style15 null\"></td>\n",
    "          </tr>\n",
    "          <tr class=\"row7\">\n",
    "            <td class=\"column0 style9 s\">RandomForest</td>\n",
    "            <td class=\"column1 style2 s\">77.0%</td>\n",
    "            <td class=\"column2 style6 s\">80.0%</td>\n",
    "            <td class=\"column3 style9 s\">0.84</td>\n",
    "            <td class=\"column4 style14 null\"></td>\n",
    "          </tr>\n",
    "        </tbody>\n",
    "    </table>\n",
    "\n",
    "### Traitement des données manquantes\n",
    "\n",
    "La suppression des lignes avec des données manquantes résulte en une perte d'information. On doit donc conserver ces lignes en remplaçant ces données par une valeur bien choisie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer as Imputer\n",
    "\n",
    "X_cat = np.copy(X[:, col_cat])\n",
    "\n",
    "for col_id in range(len(col_cat)):\n",
    "    unique_val, val_idx = np.unique(X_cat[:, col_id], return_inverse=True)\n",
    "    X_cat[:, col_id] = val_idx\n",
    "    \n",
    "imp_cat = Imputer(missing_values=0, strategy='most_frequent')\n",
    "X_cat[:, range(5)] = imp_cat.fit_transform(X_cat[:, range(5)])\n",
    "\n",
    "\n",
    "X_num = np.copy(X[:, col_num])\n",
    "X_num[X_num == '?'] = np.nan\n",
    "X_num = X_num.astype(float)\n",
    "imp_num = Imputer(missing_values=np.nan, strategy='mean')\n",
    "X_num = imp_num.fit_transform(X_num)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans notre cas, nous remplaçons les données manquantes selon la procédure suivantes :\n",
    "- Pour les données catégorielles : on utilise la valeur la plus fréquente dans la colonne\n",
    "- Pour les données numériques : on utilise la moyenne des *features* sur la colonne\n",
    "\n",
    "Dans notre cas, le nombre de lignes manquantes est faible par rapport au nombre de lignes dans le fichier. Par conséquent cette procédure influe peu sur les performances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traitement des variables catégorielles et concaténation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la partie précédente, nous nous sommes restreints aux données numériques. Il serait intéressant de trouver une solution pour exploiter les données catégorielles afin de rajouter de l'information dans la base de données.\n",
    "\n",
    "Pour exploiter les données catégorielles, nous allons nous pencher sur l'encodage One-Hot : il consiste à transformer une variable catégorielle à $m$ modalités en $m$ variables binaires.\n",
    "Nous pourrons ensuite concaténer les variables encodées en binaire avec les données numériques normalisées et tester à nouveau les classifieurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NBayes ( 0.7 ms)\n",
      "\t Accuracy : 71.0 +/- 6.0 %\n",
      "\t AUROC : 0.88 +/- 0.04\n",
      "\t Précision : 88.0 +/- 5.8 %\n",
      "Tree ( 3.1 ms)\n",
      "\t Accuracy : 79.0 +/- 3.4 %\n",
      "\t AUROC : 0.79 +/- 0.03\n",
      "\t Précision : 78.0 +/- 5.0 %\n",
      "MLP ( 444.5 ms)\n",
      "\t Accuracy : 81.0 +/- 9.7 %\n",
      "\t AUROC : 0.91 +/- 0.04\n",
      "\t Précision : 67.0 +/- 34.3 %\n",
      "KNN ( 1.6 ms)\n",
      "\t Accuracy : 86.0 +/- 4.2 %\n",
      "\t AUROC : 0.92 +/- 0.04\n",
      "\t Précision : 88.0 +/- 6.2 %\n",
      "Bagging ( 120.0 ms)\n",
      "\t Accuracy : 85.0 +/- 3.2 %\n",
      "\t AUROC : 0.92 +/- 0.04\n",
      "\t Précision : 84.0 +/- 7.2 %\n",
      "Adaboost ( 72.7 ms)\n",
      "\t Accuracy : 85.0 +/- 4.5 %\n",
      "\t AUROC : 0.91 +/- 0.04\n",
      "\t Précision : 81.0 +/- 8.7 %\n",
      "Randomforest ( 58.6 ms)\n",
      "\t Accuracy : 87.0 +/- 3.7 %\n",
      "\t AUROC : 0.93 +/- 0.03\n",
      "\t Précision : 84.0 +/- 9.6 %\n"
     ]
    }
   ],
   "source": [
    "X_cat_bin = OneHotEncoder().fit_transform(X_cat).toarray()\n",
    "\n",
    "X_num_scale = StandardScaler().fit_transform(X_num)\n",
    "X_tot = np.concatenate([X_num_scale, X_cat_bin], axis=1)\n",
    "\n",
    "run_classifiers(clfs, X_tot, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'utilisation des données catégorielles permet d'améliorer les performances générales de tous les algorithmes d'environ 10% (à l'exception de NBayes). Random-Forest fournit les meilleures performances avec une accuracy de 87% et une AUROC de 0.93. La précision est également satisfaisante.\n",
    "\n",
    "<table>\n",
    "<tr><td><th>Données numériques normalisées uniquement </th></td><th>Données complètes</th></tr>\n",
    "<tr><td width=\"250px\">\n",
    "<td>\n",
    "   <table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" id=\"sheet0\" class=\"sheet0 gridlines\">\n",
    "        <col class=\"col0\">\n",
    "        <col class=\"col1\">\n",
    "        <col class=\"col2\">\n",
    "        <col class=\"col3\">\n",
    "        <col class=\"col4\">\n",
    "        <tbody>\n",
    "          <tr class=\"row0\">\n",
    "            <td class=\"column0 style1 null\"></td>\n",
    "            <td class=\"column1 style1 s\">Accuracy</td>\n",
    "            <td class=\"column2 style1 s\">Précision</td>\n",
    "            <td class=\"column3 style1 s\">Auroc</td>\n",
    "            <td class=\"column4 style11 null\"></td>\n",
    "          </tr>\n",
    "          <tr class=\"row1\">\n",
    "            <td class=\"column0 style1 s\">Nbayes</td>\n",
    "            <td class=\"column1 style2 s\">71.0%</td>\n",
    "            <td class=\"column2 style6 s\">85.0%</td>\n",
    "            <td class=\"column3 style1 s\">0.79</td>\n",
    "            <td class=\"column4 style12 null\"></td>\n",
    "          </tr>\n",
    "          <tr class=\"row2\">\n",
    "            <td class=\"column0 style1 s\">CART</td>\n",
    "            <td class=\"column1 style2 s\">71.0%</td>\n",
    "            <td class=\"column2 style6 s\">66.0%</td>\n",
    "            <td class=\"column3 style8 s\">0.71</td>\n",
    "            <td class=\"column4 style13 null\"></td>\n",
    "          </tr>\n",
    "          <tr class=\"row3\">\n",
    "            <td class=\"column0 style1 s\">MLP</td>\n",
    "            <td class=\"column1 style5 s\">73.0%</td>\n",
    "            <td class=\"column2 style4 s\">70.0%</td>\n",
    "            <td class=\"column3 style3 s\">0.78</td>\n",
    "            <td class=\"column4 style11 null\"></td>\n",
    "          </tr>\n",
    "          <tr class=\"row4\">\n",
    "            <td class=\"column0 style1 s\">KNN</td>\n",
    "            <td class=\"column1 style5 s\">74.0%</td>\n",
    "            <td class=\"column2 style4 s\">87.0%</td>\n",
    "            <td class=\"column3 style4 s\">0.82</td>\n",
    "            <td class=\"column4 style12 null\"></td>\n",
    "          </tr>\n",
    "          <tr class=\"row5\">\n",
    "            <td class=\"column0 style9 s\">Bagging</td>\n",
    "            <td class=\"column1 style2 s\">77.0%</td>\n",
    "            <td class=\"column2 style6 s\">77.0%</td>\n",
    "            <td class=\"column3 style9 s\">0.83</td>\n",
    "            <td class=\"column4 style14 null\"></td>\n",
    "          </tr>\n",
    "          <tr class=\"row6\">\n",
    "            <td class=\"column0 style9 s\">Adaboost</td>\n",
    "            <td class=\"column1 style7 s\">79.0%</td>\n",
    "            <td class=\"column2 style6 s\">79.0%</td>\n",
    "            <td class=\"column3 style10 s\">0.85</td>\n",
    "            <td class=\"column4 style15 null\"></td>\n",
    "          </tr>\n",
    "          <tr class=\"row7\">\n",
    "            <td class=\"column0 style9 s\">RandomForest</td>\n",
    "            <td class=\"column1 style2 s\">77.0%</td>\n",
    "            <td class=\"column2 style6 s\">80.0%</td>\n",
    "            <td class=\"column3 style9 s\">0.84</td>\n",
    "            <td class=\"column4 style14 null\"></td>\n",
    "          </tr>\n",
    "        </tbody>\n",
    "    </table>\n",
    "    </td>\n",
    "    <td>\n",
    "            <table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" id=\"sheet0\" class=\"sheet0 gridlines\">\n",
    "        <col class=\"col0\">\n",
    "        <col class=\"col1\">\n",
    "        <col class=\"col2\">\n",
    "        <col class=\"col3\">\n",
    "        <col class=\"col4\">\n",
    "        <tbody>\n",
    "          <tr class=\"row0\">\n",
    "            <td class=\"column0 style1 null\"></td>\n",
    "            <td class=\"column1 style1 s\">Accuracy</td>\n",
    "            <td class=\"column2 style1 s\">Précision</td>\n",
    "            <td class=\"column3 style1 s\">Auroc</td>\n",
    "            <td class=\"column4 style11 null\"></td>\n",
    "          </tr>\n",
    "          <tr class=\"row1\">\n",
    "            <td class=\"column0 style1 s\">Nbayes</td>\n",
    "            <td class=\"column1 style2 s\">71.0%</td>\n",
    "            <td class=\"column2 style6 s\"><strong>88.0%</strong></td>\n",
    "            <td class=\"column3 style1 s\"><strong>0.88</strong></td>\n",
    "            <td class=\"column4 style12 null\"></td>\n",
    "          </tr>\n",
    "          <tr class=\"row2\">\n",
    "            <td class=\"column0 style1 s\">CART</td>\n",
    "            <td class=\"column1 style2 s\"><strong>79.0%</strong></td>\n",
    "            <td class=\"column2 style6 s\"><strong>78.0%</strong></td>\n",
    "            <td class=\"column3 style8 s\"><strong>0.80</strong></td>\n",
    "            <td class=\"column4 style13 null\"></td>\n",
    "          </tr>\n",
    "          <tr class=\"row3\">\n",
    "            <td class=\"column0 style1 s\">MLP</td>\n",
    "            <td class=\"column1 style5 s\"><strong>76.0%</strong></td>\n",
    "            <td class=\"column2 style4 s\"><strong>76.0%</strong></td>\n",
    "            <td class=\"column3 style3 s\"><strong>0.84</strong></td>\n",
    "            <td class=\"column4 style11 null\"></td>\n",
    "          </tr>\n",
    "          <tr class=\"row4\">\n",
    "            <td class=\"column0 style1 s\">KNN</td>\n",
    "            <td class=\"column1 style5 s\"><strong>86.0%</strong></td>\n",
    "            <td class=\"column2 style4 s\"><strong>88.0%</strong></td>\n",
    "            <td class=\"column3 style4 s\"><strong>0.92</strong></td>\n",
    "            <td class=\"column4 style12 null\"></td>\n",
    "          </tr>\n",
    "          <tr class=\"row5\">\n",
    "            <td class=\"column0 style9 s\">Bagging</td>\n",
    "            <td class=\"column1 style2 s\"><strong>86.0%</strong></td>\n",
    "            <td class=\"column2 style6 s\"><strong>84.0%</strong></td>\n",
    "            <td class=\"column3 style9 s\"><strong>0.92</strong></td>\n",
    "            <td class=\"column4 style14 null\"></td>\n",
    "          </tr>\n",
    "          <tr class=\"row6\">\n",
    "            <td class=\"column0 style9 s\">Adaboost</td>\n",
    "            <td class=\"column1 style7 s\"><strong>85.0%</strong></td>\n",
    "            <td class=\"column2 style6 s\"><strong>81.0%</strong></td>\n",
    "            <td class=\"column3 style10 s\"><strong>0.91</strong></td>\n",
    "            <td class=\"column4 style15 null\"></td>\n",
    "          </tr>\n",
    "          <tr class=\"row7\">\n",
    "            <td class=\"column0 style9 s\">RandomForest</td>\n",
    "            <td class=\"column1 style2 s\"><strong>87.0%</strong></td>\n",
    "            <td class=\"column2 style6 s\"><strong>86.0%</strong></td>\n",
    "            <td class=\"column3 style9 s\"><strong>0.93</strong></td>\n",
    "            <td class=\"column4 style14 null\"></td>\n",
    "          </tr>\n",
    "        </tbody>\n",
    "    </table>\n",
    "    </td>\n",
    "</td><td width=\"500px\">\n",
    "\n",
    "\n",
    "</td></tr> </table>\n",
    "\n",
    "## Apprentissage sur données textuelles\n",
    "On termine cette étude par une analyse de données textuelles. En l'occurrence, on cherche à identifier des spams dans une base de SMS. \n",
    "### Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de l'échantillon :  (5571,)\n",
      "Nombre d'entrée 0 :  4824  ( 86.59 %)\n",
      "Nombre d'entrée 1 :  747  ( 13.41 %)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"./SMSSpamCollection.data\", sep=\"\\t\")\n",
    "data_array = data.values\n",
    "X = data_array[:,1]\n",
    "Y = data_array[:,0]\n",
    "\n",
    "Y = np.where(Y=='spam', 1, Y)\n",
    "Y = np.where(Y=='ham', 0, Y)\n",
    "Y = Y.astype(np.int)\n",
    "\n",
    "print(\"Taille de l'échantillon : \", X.shape)\n",
    "\n",
    "n_zeros = np.histogram(Y)[0][0]\n",
    "n_ones = np.histogram(Y)[0][-1]\n",
    "print(\"Nombre d'entrée 0 : \", n_zeros, \" (\", round(n_zeros*100/len(Y), 2),\"%)\")\n",
    "print(\"Nombre d'entrée 1 : \", n_ones, \" (\", round(n_ones*100/len(Y), 2),\"%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La base contient 5571 SMS dont 13% sont des spams.\n",
    "### Count Vectorizer\n",
    "Une première étape consiste à transformer les données textuelles en données numériques afin de pouvoir les exploiter par un algorithme de classification. Pour cela, on propose d'encoder chaque mot présent dans la base grâce à une variable binaire   (*True* si le mot est présent dans la ligne et *False* sinon). Cela produit une matrice dite *sparse* des données. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5571, 300)\n",
      "Tree ( 426.1 ms)\n",
      "\t Accuracy : 97.0 +/- 0.9 %\n",
      "\t AUROC : 0.93 +/- 0.02\n",
      "\t Précision : 87.0 +/- 0.9 %\n",
      "MLP ( 2537.5 ms)\n",
      "\t Accuracy : 98.0 +/- 0.6 %\n",
      "\t AUROC : 0.97 +/- 0.01\n",
      "\t Précision : 93.0 +/- 2.0 %\n",
      "KNN ( 4.6 ms)\n",
      "\t Accuracy : 90.0 +/- 1.3 %\n",
      "\t AUROC : 0.94 +/- 0.01\n",
      "\t Précision : 100.0 +/- 0.0 %\n",
      "Bagging ( 9612.2 ms)\n",
      "\t Accuracy : 97.0 +/- 0.9 %\n",
      "\t AUROC : 0.97 +/- 0.01\n",
      "\t Précision : 88.0 +/- 1.4 %\n",
      "Adaboost ( 972.3 ms)\n",
      "\t Accuracy : 97.0 +/- 0.9 %\n",
      "\t AUROC : 0.97 +/- 0.01\n",
      "\t Précision : 94.0 +/- 1.6 %\n",
      "Randomforest ( 882.9 ms)\n",
      "\t Accuracy : 97.0 +/- 0.9 %\n",
      "\t AUROC : 0.98 +/- 0.01\n",
      "\t Précision : 93.0 +/- 1.9 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=300,stop_words=\"english\")\n",
    "X_vec = vectorizer.fit_transform(X)\n",
    "print(X_vec.shape)\n",
    "\n",
    "\n",
    "clfs = {\"Tree\" : DecisionTreeClassifier(),\n",
    "\"MLP\" : MLPClassifier([20, 10]),\n",
    "\"KNN\" : KNeighborsClassifier(n_neighbors=19, p=1),\n",
    "\"Bagging\" : BaggingClassifier(n_estimators=50),\n",
    "\"Adaboost\" : AdaBoostClassifier(n_estimators=50),\n",
    "\"Randomforest\" : RandomForestClassifier(n_estimators=50)}\n",
    "\n",
    "run_classifiers(clfs, X_vec.toarray(), Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour l'instant on utilise la totalité des données, soit une matrice de données *sparse* de taille $5571\\times 8711$. Les temps de calculs sont très longs, mais les performances sont excellentes, notamment pour le MLP* qui parvient à atteindre une classification quasi-parfaite.\n",
    "\n",
    "   <table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" id=\"sheet0\" class=\"sheet0 gridlines\">\n",
    "        <col class=\"col0\">\n",
    "        <col class=\"col1\">\n",
    "        <col class=\"col2\">\n",
    "        <col class=\"col3\">\n",
    "        <col class=\"col4\">\n",
    "        <tbody>\n",
    "          <tr class=\"row0\">\n",
    "            <td class=\"column0 style1 null\"></td>\n",
    "            <td class=\"column1 style1 s\">Accuracy</td>\n",
    "            <td class=\"column2 style1 s\">Précision</td>\n",
    "            <td class=\"column3 style1 s\">Auroc</td>\n",
    "            <td class=\"column4 style6 s\">time</td>\n",
    "          </tr>\n",
    "          <tr class=\"row1\">\n",
    "            <td class=\"column0 style1 s\">CART</td>\n",
    "            <td class=\"column1 style2 s\">96.0%</td>\n",
    "            <td class=\"column2 style3 s\">88.0%</td>\n",
    "            <td class=\"column3 style1 s\">0.93</td>\n",
    "            <td class=\"column4 style5 s\">129.7ms</td>\n",
    "          </tr>\n",
    "          <tr class=\"row2\">\n",
    "            <td class=\"column0 style1 s\">MLP</td>\n",
    "            <td class=\"column1 style4 s\"><strong/>98.0%</strong></td>\n",
    "            <td class=\"column2 style3 s\"><strong>93.0%</strong></td>\n",
    "            <td class=\"column3 style5 s\">0.97</td>\n",
    "            <td class=\"column4 style5 s\">6818ms</td>\n",
    "          </tr>\n",
    "          <tr class=\"row3\">\n",
    "            <td class=\"column0 style5 s\">KNN</td>\n",
    "            <td class=\"column1 style2 s\">90.0%</td>\n",
    "            <td class=\"column2 style3 s\"><strong>100.0%<strong></td>\n",
    "            <td class=\"column3 style5 s\">0.93</td>\n",
    "            <td class=\"column4 style1 s\"><strong>0.9ms</strong></td>\n",
    "          </tr>\n",
    "          <tr class=\"row4\">\n",
    "            <td class=\"column0 style6 s\">Bagging</td>\n",
    "            <td class=\"column1 style2 s\">97.0%</td>\n",
    "            <td class=\"column2 style3 s\">89.0%</td>\n",
    "            <td class=\"column3 style3 s\">0.97</td>\n",
    "            <td class=\"column4 style5 s\">4439ms</td>\n",
    "          </tr>\n",
    "          <tr class=\"row5\">\n",
    "            <td class=\"column0 style6 s\">Adaboost</td>\n",
    "            <td class=\"column1 style2 s\">97.0%</td>\n",
    "            <td class=\"column2 style3 s\">94.0%</td>\n",
    "            <td class=\"column3 style6 s\">0.97</td>\n",
    "            <td class=\"column4 style7 s\">1687ms</td>\n",
    "          </tr>\n",
    "          <tr class=\"row6\">\n",
    "            <td class=\"column0 style6 s\">RandomForest</td>\n",
    "            <td class=\"column1 style2 s\">98.0%</td>\n",
    "            <td class=\"column2 style3 s\"><strong>93.0%</strong></td>\n",
    "            <td class=\"column3 style7 s\"><strong>0.98</strong></td>\n",
    "            <td class=\"column4 style7 s\">1401ms</td>\n",
    "          </tr>\n",
    "          <tr class=\"row7\">\n",
    "            <td class=\"column0 style8 null\"></td>\n",
    "            <td class=\"column1 style9 null\"></td>\n",
    "            <td class=\"column2 style10 null\"></td>\n",
    "            <td class=\"column3 style8 null\"></td>\n",
    "            <td class=\"column4 style8 null\"></td>\n",
    "          </tr>\n",
    "        </tbody>\n",
    "    </table>\n",
    "\n",
    "### TF-IDF term weighting\n",
    "Cette méthode est très gourmande en emplacement mémoire et en temps de calcul (notamment sur des bases de données plus conséquentes). Une solution serait d'utiliser TF-IDF : utiliser TF-IDF plutôt que le nombre d'occurrences de chaque mot dans un document permet de diminuer l'impact des mots à la fois très fréquents dans le texte et portant moins d'informations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree ( 440.1 ms)\n",
      "\t Accuracy : 96.0 +/- 0.8 %\n",
      "\t AUROC : 0.93 +/- 0.02\n",
      "\t Précision : 88.0 +/- 1.2 %\n",
      "MLP ( 2870.3 ms)\n",
      "\t Accuracy : 98.0 +/- 0.6 %\n",
      "\t AUROC : 0.97 +/- 0.02\n",
      "\t Précision : 93.0 +/- 2.9 %\n",
      "KNN ( 1.8 ms)\n",
      "\t Accuracy : 90.0 +/- 1.3 %\n",
      "\t AUROC : 0.94 +/- 0.01\n",
      "\t Précision : 100.0 +/- 0.0 %\n",
      "Bagging ( 9896.7 ms)\n",
      "\t Accuracy : 97.0 +/- 0.8 %\n",
      "\t AUROC : 0.97 +/- 0.01\n",
      "\t Précision : 88.0 +/- 1.6 %\n",
      "Adaboost ( 856.0 ms)\n",
      "\t Accuracy : 97.0 +/- 0.9 %\n",
      "\t AUROC : 0.97 +/- 0.01\n",
      "\t Précision : 94.0 +/- 1.6 %\n",
      "Randomforest ( 903.6 ms)\n",
      "\t Accuracy : 97.0 +/- 1.1 %\n",
      "\t AUROC : 0.98 +/- 0.01\n",
      "\t Précision : 93.0 +/- 3.1 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "transformer = TfidfTransformer()\n",
    "X_Tfidf = transformer.fit_transform(X_vec)\n",
    "run_classifiers(clfs, X_vec.toarray(), Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous ne tenons compte que des 1000 termes les plus fréquents et nous retirons les mots anglais qui ne portent pas toujours d'informations.\n",
    "<table>\n",
    "<tr><td><th>Count Vectorizer + TF-IDF\t </th></td><th>Count Vectorizer + TF IDF transformer</th></tr>\n",
    "<tr><td width=\"250px\">\n",
    "<td>\n",
    "  <table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" id=\"sheet0\" class=\"sheet0 gridlines\">\n",
    "        <col class=\"col0\">\n",
    "        <col class=\"col1\">\n",
    "        <col class=\"col2\">\n",
    "        <col class=\"col3\">\n",
    "        <col class=\"col4\">\n",
    "        <tbody>\n",
    "          <tr class=\"row0\">\n",
    "            <td class=\"column0 style1 null\"></td>\n",
    "            <td class=\"column1 style1 s\">Accuracy</td>\n",
    "            <td class=\"column2 style1 s\">Précision</td>\n",
    "            <td class=\"column3 style1 s\">Auroc</td>\n",
    "            <td class=\"column4 style6 s\">time</td>\n",
    "          </tr>\n",
    "          <tr class=\"row1\">\n",
    "            <td class=\"column0 style1 s\">CART</td>\n",
    "            <td class=\"column1 style2 s\">96.0%</td>\n",
    "            <td class=\"column2 style3 s\">88.0%</td>\n",
    "            <td class=\"column3 style1 s\">0.93</td>\n",
    "            <td class=\"column4 style5 s\">129.7ms</td>\n",
    "          </tr>\n",
    "          <tr class=\"row2\">\n",
    "            <td class=\"column0 style1 s\">MLP</td>\n",
    "            <td class=\"column1 style4 s\"><strong/>98.0%</strong></td>\n",
    "            <td class=\"column2 style3 s\"><strong>93.0%</strong></td>\n",
    "            <td class=\"column3 style5 s\">0.97</td>\n",
    "            <td class=\"column4 style5 s\">6818ms</td>\n",
    "          </tr>\n",
    "          <tr class=\"row3\">\n",
    "            <td class=\"column0 style5 s\">KNN</td>\n",
    "            <td class=\"column1 style2 s\">90.0%</td>\n",
    "            <td class=\"column2 style3 s\"><strong>100.0%<strong></td>\n",
    "            <td class=\"column3 style5 s\">0.93</td>\n",
    "            <td class=\"column4 style1 s\"><strong>0.9ms</strong></td>\n",
    "          </tr>\n",
    "          <tr class=\"row4\">\n",
    "            <td class=\"column0 style6 s\">Bagging</td>\n",
    "            <td class=\"column1 style2 s\">97.0%</td>\n",
    "            <td class=\"column2 style3 s\">89.0%</td>\n",
    "            <td class=\"column3 style3 s\">0.97</td>\n",
    "            <td class=\"column4 style5 s\">4439ms</td>\n",
    "          </tr>\n",
    "          <tr class=\"row5\">\n",
    "            <td class=\"column0 style6 s\">Adaboost</td>\n",
    "            <td class=\"column1 style2 s\">97.0%</td>\n",
    "            <td class=\"column2 style3 s\">94.0%</td>\n",
    "            <td class=\"column3 style6 s\">0.97</td>\n",
    "            <td class=\"column4 style7 s\">1687ms</td>\n",
    "          </tr>\n",
    "          <tr class=\"row6\">\n",
    "            <td class=\"column0 style6 s\">RandomForest</td>\n",
    "            <td class=\"column1 style2 s\">98.0%</td>\n",
    "            <td class=\"column2 style3 s\"><strong>93.0%</strong></td>\n",
    "            <td class=\"column3 style7 s\"><strong>0.98</strong></td>\n",
    "            <td class=\"column4 style7 s\">1401ms</td>\n",
    "          </tr>\n",
    "          <tr class=\"row7\">\n",
    "            <td class=\"column0 style8 null\"></td>\n",
    "            <td class=\"column1 style9 null\"></td>\n",
    "            <td class=\"column2 style10 null\"></td>\n",
    "            <td class=\"column3 style8 null\"></td>\n",
    "            <td class=\"column4 style8 null\"></td>\n",
    "          </tr>\n",
    "        </tbody>\n",
    "    </table>\n",
    "\n",
    "<td>\n",
    "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" id=\"sheet0\" class=\"sheet0 gridlines\">\n",
    "        <col class=\"col0\">\n",
    "        <col class=\"col1\">\n",
    "        <col class=\"col2\">\n",
    "        <col class=\"col3\">\n",
    "        <col class=\"col4\">\n",
    "        <tbody>\n",
    "          <tr class=\"row0\">\n",
    "            <td class=\"column0 style1 null\"></td>\n",
    "            <td class=\"column1 style1 s\">Accuracy</td>\n",
    "            <td class=\"column2 style1 s\">Précision</td>\n",
    "            <td class=\"column3 style1 s\">Auroc</td>\n",
    "            <td class=\"column4 style6 s\">time</td>\n",
    "          </tr>\n",
    "          <tr class=\"row1\">\n",
    "            <td class=\"column0 style1 s\">CART</td>\n",
    "            <td class=\"column1 style2 s\"><strong>97.0%</strong></td>\n",
    "            <td class=\"column2 style3 s\">88.0%</td>\n",
    "            <td class=\"column3 style1 s\">0.93</td>\n",
    "            <td class=\"column4 style5 s\"><strong>128.5ms</strong></td>\n",
    "          </tr>\n",
    "          <tr class=\"row2\">\n",
    "            <td class=\"column0 style1 s\">MLP</td>\n",
    "            <td class=\"column1 style4 s\">98.0%</td>\n",
    "            <td class=\"column2 style3 s\">96.0%</td>\n",
    "            <td class=\"column3 style5 s\"><strong>0.99</strong></td>\n",
    "            <td class=\"column4 style5 s\"><strong>2200ms</strong></td>\n",
    "          </tr>\n",
    "          <tr class=\"row3\">\n",
    "            <td class=\"column0 style5 s\">KNN</td>\n",
    "            <td class=\"column1 style2 s\">88.0%</td>\n",
    "            <td class=\"column2 style3 s\">100.0%</td>\n",
    "            <td class=\"column3 style5 s\">0.83</td>\n",
    "            <td class=\"column4 style1 s\">1.1ms</td>\n",
    "          </tr>\n",
    "          <tr class=\"row4\">\n",
    "            <td class=\"column0 style6 s\">Bagging</td>\n",
    "            <td class=\"column1 style2 s\">97.0%</td>\n",
    "            <td class=\"column2 style3 s\">91.0%</td>\n",
    "            <td class=\"column3 style3 s\">0.98</td>\n",
    "            <td class=\"column4 style5 s\"><strong>3815ms</strong></td>\n",
    "          </tr>\n",
    "          <tr class=\"row5\">\n",
    "            <td class=\"column0 style6 s\">Adaboost</td>\n",
    "            <td class=\"column1 style2 s\">97.0%</td>\n",
    "            <td class=\"column2 style3 s\">94.0%</td>\n",
    "            <td class=\"column3 style6 s\">0.97</td>\n",
    "            <td class=\"column4 style7 s\"><strong>157ms</strong></td>\n",
    "          </tr>\n",
    "          <tr class=\"row6\">\n",
    "            <td class=\"column0 style6 s\">RandomForest</td>\n",
    "            <td class=\"column1 style2 s\">98.0%</td>\n",
    "            <td class=\"column2 style3 s\">98.0%</td>\n",
    "            <td class=\"column3 style7 s\">0.99</td>\n",
    "            <td class=\"column4 style7 s\"><strong>293.9ms</strong></td>\n",
    "          </tr>\n",
    "          <tr class=\"row7\">\n",
    "            <td class=\"column0 style8 null\"></td>\n",
    "            <td class=\"column1 style9 null\"></td>\n",
    "            <td class=\"column2 style10 null\"></td>\n",
    "            <td class=\"column3 style8 null\"></td>\n",
    "            <td class=\"column4 style8 null\"></td>\n",
    "          </tr>\n",
    "        </tbody>\n",
    "    </table>\n",
    "</td>\n",
    "</td><td width=\"500px\">\n",
    "\n",
    "\n",
    "</td></tr> </table>\n",
    "\n",
    "L'utilisation de TF-IDF permet de réduire le temps de calcul en n'impactant pas trop les performances générales.\n",
    "\n",
    "### TruncatedSVD\n",
    "Afin de limiter l'utilisation de l'espace mémoire et du temps de calcul, on fait appel à un algorithme de réduction de dimension sur le même principe que PCA, mais sans centrer les features. (NB : en cas de crash, il faut relancer le programme bloc par bloc, à partir du chargement des données textuelles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree ( 109.7 ms)\n",
      "\t Accuracy : 96.0 +/- 0.7 %\n",
      "\t AUROC : 0.9 +/- 0.02\n",
      "\t Précision : 81.0 +/- 2.6 %\n",
      "MLP ( 1995.8 ms)\n",
      "\t Accuracy : 97.0 +/- 0.7 %\n",
      "\t AUROC : 0.98 +/- 0.01\n",
      "\t Précision : 91.0 +/- 0.7 %\n",
      "KNN ( 0.7 ms)\n",
      "\t Accuracy : 96.0 +/- 0.9 %\n",
      "\t AUROC : 0.97 +/- 0.01\n",
      "\t Précision : 88.0 +/- 3.2 %\n",
      "Bagging ( 3041.9 ms)\n",
      "\t Accuracy : 97.0 +/- 0.9 %\n",
      "\t AUROC : 0.97 +/- 0.01\n",
      "\t Précision : 93.0 +/- 0.5 %\n",
      "Adaboost ( 677.9 ms)\n",
      "\t Accuracy : 96.0 +/- 0.9 %\n",
      "\t AUROC : 0.97 +/- 0.01\n",
      "\t Précision : 88.0 +/- 1.4 %\n",
      "Randomforest ( 471.0 ms)\n",
      "\t Accuracy : 97.0 +/- 0.8 %\n",
      "\t AUROC : 0.97 +/- 0.01\n",
      "\t Précision : 95.0 +/- 2.1 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=30)\n",
    "svd.fit(X_Tfidf)\n",
    "X_svd = svd.transform(X_Tfidf)\n",
    "\n",
    "\n",
    "run_classifiers(clfs, X_svd, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr><td><th>Count Vectorizer + TF-IDF\t </th></td><th>Count Vectorizer + TF IDF transformer + SVDTruncated</th></tr>\n",
    "<tr><td width=\"250px\">\n",
    "<td>\n",
    "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" id=\"sheet0\" class=\"sheet0 gridlines\">\n",
    "        <col class=\"col0\">\n",
    "        <col class=\"col1\">\n",
    "        <col class=\"col2\">\n",
    "        <col class=\"col3\">\n",
    "        <col class=\"col4\">\n",
    "        <tbody>\n",
    "          <tr class=\"row0\">\n",
    "            <td class=\"column0 style1 null\"></td>\n",
    "            <td class=\"column1 style1 s\">Accuracy</td>\n",
    "            <td class=\"column2 style1 s\">Précision</td>\n",
    "            <td class=\"column3 style1 s\">Auroc</td>\n",
    "            <td class=\"column4 style6 s\">time</td>\n",
    "          </tr>\n",
    "          <tr class=\"row1\">\n",
    "            <td class=\"column0 style1 s\">CART</td>\n",
    "            <td class=\"column1 style2 s\"><strong>97.0%</strong></td>\n",
    "            <td class=\"column2 style3 s\"><strong>88.0%</strong></td>\n",
    "            <td class=\"column3 style1 s\"><strong>0.93</strong></td>\n",
    "            <td class=\"column4 style5 s\">128.5ms</td>\n",
    "          </tr>\n",
    "          <tr class=\"row2\">\n",
    "            <td class=\"column0 style1 s\">MLP</td>\n",
    "            <td class=\"column1 style4 s\"><strong>98.0%</strong></td>\n",
    "            <td class=\"column2 style3 s\"><strong>96.0%</strong></td>\n",
    "            <td class=\"column3 style5 s\"><strong>0.99</strong></td>\n",
    "            <td class=\"column4 style5 s\">2200ms</td>\n",
    "          </tr>\n",
    "          <tr class=\"row3\">\n",
    "            <td class=\"column0 style5 s\">KNN</td>\n",
    "            <td class=\"column1 style2 s\">88.0%</td>\n",
    "            <td class=\"column2 style3 s\"><strong>100.0%</strong></td>\n",
    "            <td class=\"column3 style5 s\">0.83</td>\n",
    "            <td class=\"column4 style1 s\"><strong>1.1ms</strong></td>\n",
    "          </tr>\n",
    "          <tr class=\"row4\">\n",
    "            <td class=\"column0 style6 s\">Bagging</td>\n",
    "            <td class=\"column1 style2 s\">97.0%</td>\n",
    "            <td class=\"column2 style3 s\">91.0%</td>\n",
    "            <td class=\"column3 style3 s\"><strong>0.98</strong></td>\n",
    "            <td class=\"column4 style5 s\">3815ms</td>\n",
    "          </tr>\n",
    "          <tr class=\"row5\">\n",
    "            <td class=\"column0 style6 s\">Adaboost</td>\n",
    "            <td class=\"column1 style2 s\"><strong>97.0%</strong></td>\n",
    "            <td class=\"column2 style3 s\"><strong>94.0%</strong></td>\n",
    "            <td class=\"column3 style6 s\">0.97</td>\n",
    "            <td class=\"column4 style7 s\"><strong>157ms</strong></td>\n",
    "          </tr>\n",
    "          <tr class=\"row6\">\n",
    "            <td class=\"column0 style6 s\">RandomForest</td>\n",
    "            <td class=\"column1 style2 s\"><strong>98.0%</strong></td>\n",
    "            <td class=\"column2 style3 s\"><strong>98.0%</strong></td>\n",
    "            <td class=\"column3 style7 s\"><strong>0.99<strong></td>\n",
    "            <td class=\"column4 style7 s\">293.9ms</td>\n",
    "          </tr>\n",
    "          <tr class=\"row7\">\n",
    "            <td class=\"column0 style8 null\"></td>\n",
    "            <td class=\"column1 style9 null\"></td>\n",
    "            <td class=\"column2 style10 null\"></td>\n",
    "            <td class=\"column3 style8 null\"></td>\n",
    "            <td class=\"column4 style8 null\"></td>\n",
    "          </tr>\n",
    "        </tbody>\n",
    "    </table>\n",
    "</td>\n",
    "\n",
    "<td>\n",
    "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" id=\"sheet0\" class=\"sheet0 gridlines\">\n",
    "        <col class=\"col0\">\n",
    "        <col class=\"col1\">\n",
    "        <col class=\"col2\">\n",
    "        <col class=\"col3\">\n",
    "        <col class=\"col4\">\n",
    "        <tbody>\n",
    "          <tr class=\"row0\">\n",
    "            <td class=\"column0 style1 null\"></td>\n",
    "            <td class=\"column1 style1 s\">Accuracy</td>\n",
    "            <td class=\"column2 style1 s\">Précision</td>\n",
    "            <td class=\"column3 style1 s\">Auroc</td>\n",
    "            <td class=\"column4 style6 s\">time</td>\n",
    "          </tr>\n",
    "          <tr class=\"row1\">\n",
    "            <td class=\"column0 style1 s\">CART</td>\n",
    "            <td class=\"column1 style2 s\">96.0%</td>\n",
    "            <td class=\"column2 style3 s\">84.0%</td>\n",
    "            <td class=\"column3 style1 s\">0.92</td>\n",
    "            <td class=\"column4 style5 s\"><strong>52.5ms</strong></td>\n",
    "          </tr>\n",
    "          <tr class=\"row2\">\n",
    "            <td class=\"column0 style1 s\">MLP</td>\n",
    "            <td class=\"column1 style4 s\">97.0%</td>\n",
    "            <td class=\"column2 style3 s\">89.0%</td>\n",
    "            <td class=\"column3 style5 s\">0.97</td>\n",
    "            <td class=\"column4 style5 s\"><strong>1884ms</strong></td>\n",
    "          </tr>\n",
    "          <tr class=\"row3\">\n",
    "            <td class=\"column0 style5 s\">KNN</td>\n",
    "            <td class=\"column1 style2 s\"><strong>96.0%</strong></td>\n",
    "            <td class=\"column2 style3 s\">89.0%</td>\n",
    "            <td class=\"column3 style5 s\"><strong>0.97</strong></td>\n",
    "            <td class=\"column4 style1 s\">3.3ms</td>\n",
    "          </tr>\n",
    "          <tr class=\"row4\">\n",
    "            <td class=\"column0 style6 s\">Bagging</td>\n",
    "            <td class=\"column1 style2 s\">97.0%</td>\n",
    "            <td class=\"column2 style3 s\"><strong>93.0%</strong></td>\n",
    "            <td class=\"column3 style3 s\">0.97</td>\n",
    "            <td class=\"column4 style5 s\"><strong>1455ms</strong></td>\n",
    "          </tr>\n",
    "          <tr class=\"row5\">\n",
    "            <td class=\"column0 style6 s\">Adaboost</td>\n",
    "            <td class=\"column1 style2 s\">96.0%</td>\n",
    "            <td class=\"column2 style3 s\">89.0%</td>\n",
    "            <td class=\"column3 style6 s\">0.97</td>\n",
    "            <td class=\"column4 style7 s\">353ms</td>\n",
    "          </tr>\n",
    "          <tr class=\"row6\">\n",
    "            <td class=\"column0 style6 s\">RandomForest</td>\n",
    "            <td class=\"column1 style2 s\">97.0%</td>\n",
    "            <td class=\"column2 style3 s\">95.0%</td>\n",
    "            <td class=\"column3 style7 s\">0.98</td>\n",
    "            <td class=\"column4 style7 s\"><strong>285ms</strong></td>\n",
    "          </tr>\n",
    "          <tr class=\"row7\">\n",
    "            <td class=\"column0 style8 null\"></td>\n",
    "            <td class=\"column1 style9 null\"></td>\n",
    "            <td class=\"column2 style10 null\"></td>\n",
    "            <td class=\"column3 style8 null\"></td>\n",
    "            <td class=\"column4 style8 null\"></td>\n",
    "          </tr>\n",
    "        </tbody>\n",
    "    </table>\n",
    "</td>\n",
    "</td><td width=\"500px\">\n",
    "</td></tr> </table>\n",
    "\n",
    "Finalement, les résultats du Truncated SVD sont en **demi-teinte** : la procédure permet effectivement de limiter le temps de calcul de certains algorithmes et d'améliorer légèrement les performances (notamment pour *Bagging* et *KNN*) mais a un **effet négatif** sur d'autres algorithmes.\n",
    "\n",
    "### Pipeline\n",
    "\n",
    "On termine par la mise en place d'un Pipeline permettant de traiter des jeux de données textuelles. L'algorithme Random-Forest a été choisi pour ses bonnes performances et son temps d'entrainement réduit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 98.0 +/- 0.9 %\n",
      "AUROC : 0.98 +/- 0.01\n",
      "Précision : 92.0 +/- 1.7 %\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([(\"CountTFVectorizer\", CountVectorizer(max_features=300,stop_words=\"english\")), \n",
    "                     (\"RandomForest\", RandomForestClassifier(n_estimators=50))])\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "kf2 = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "clf = pipeline\n",
    "cv = cross_validate(clf, X, Y, cv=kf, scoring=scoring)\n",
    "cv2 = cross_validate(clf, X, Y, cv=kf2, scoring={\"Precision\" : make_scorer(precision_score)})\n",
    "\n",
    "cv_time = cv['fit_time']\n",
    "cv_acc = cv['test_Accuracy']\n",
    "cv_auc = cv[\"test_AUC\"]\n",
    "cv_prec = cv2[\"test_Precision\"]\n",
    "\n",
    "print(\"Accuracy :\", round(np.mean(cv_acc),2)*100,\"+/-\", round(np.std(cv_acc)*100,1),\"%\")\n",
    "print(\"AUROC :\", round(np.mean(cv_auc),2),\"+/-\", round(np.std(cv_auc),2))\n",
    "print(\"Précision :\", round(np.mean(cv_prec),2)*100,\"+/-\", round(np.std(cv_prec)*100,1),\"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce pipeline permet de séparer efficacement les spams des SMS intéressants. Nous allons le tester avec un autre jeu de données *Yelp* d'avis sur des lieux de tourismes. Le fichier contient 47 371 avis textuels accompagnés d'une note de 1 à 5. On entraine notre Pipeline sur ce jeu de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de l'échantillon :  (47371,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./yelp-text-by-stars.csv\", sep=\";\", encoding = \"ISO-8859-1\")\n",
    "data_array = data.values\n",
    "X = data_array[:,1]\n",
    "Y = data_array[:,0]\n",
    "\n",
    "Y = Y.astype(np.int)\n",
    "print(\"Taille de l'échantillon : \", X.shape)\n",
    "plt.title(\"Répartition des données\")\n",
    "plt.xlabel(\"Nombre d'étoiles\")\n",
    "plt.ylabel(\"Nombre d'occurences\")\n",
    "plt.hist(Y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le fichier contient 47 371 avis textuels accompagnés d'une note de 1 à 5. On entraine notre Pipeline sur ce jeu de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 54.0 +/- 0.3 %\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "cv = cross_validate(pipeline, X, Y, cv=kf, scoring={\"Accuracy\" : make_scorer(accuracy_score)})\n",
    "cv_acc = cv['test_Accuracy']\n",
    "print(\"Accuracy :\", round(np.mean(cv_acc),2)*100,\"+/-\", round(np.std(cv_acc)*100,1),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La classification doit être faite sur 5 catégories différentes, ce qui la rend plus difficile. Cependant, notre pipeline permet d'obtenir une précision correcte (57 %) en un minimum de lignes de code (mais avec un temps de calcul très grand).\n",
    "\n",
    "Pour améliorer les performances, on peut également se ramener à une classification binaire. \n",
    "On associe la classe 1 aux lieux disposant de 4 ou 5 étoiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 81.0 +/- 0.2 %\n"
     ]
    }
   ],
   "source": [
    "Y[Y<4] = 0\n",
    "Y[Y>3]= 1\n",
    "\n",
    "cv = cross_validate(pipeline, X, Y, cv=kf, scoring={\"Accuracy\" : make_scorer(accuracy_score)})\n",
    "cv_acc = cv['test_Accuracy']\n",
    "print(\"Accuracy :\", round(np.mean(cv_acc),2)*100,\"+/-\", round(np.std(cv_acc)*100,1),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effectivement, cela permet d'augmenter l'accuracy d'environ 46%, ce qui n'est pas négligeable, mais nous perdons cependant de l'information dans le procédé."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Ce TP dresse un tableau assez large des différentes méthodes et techniques pouvant intervenir dans une procédure de\n",
    "*Machine Learning*. On notera finalement l'importance d'un bon traitement des données en amont de l'algorithme \n",
    "d'apprentissage à proprement parlé pour améliorer les performances et le temps de calculs (PCA, Normalisation, \n",
    "Encodage OneHot, Imputer). \n",
    "\n",
    "Les algorithmes sont également sensibles aux hyperparamètres qu'il faut choisir correctement, c'est pourquoi des \n",
    "procédures de tests de ces paramètres peuvent être nécessaires. Enfin, travailler avec des données textuelles augmente\n",
    "la difficulté de l'apprentissage : il faut savoir trouver la transformation adéquate pour que ces données soient exploitables par les algorithmes classiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
