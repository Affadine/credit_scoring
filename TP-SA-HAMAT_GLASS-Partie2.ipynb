{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(threshold=10000,suppress=True)\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb of columns 16\n"
     ]
    }
   ],
   "source": [
    "# Import du jeu de données\n",
    "dfCredit = pd.read_csv('credit.data', sep='\\t')\n",
    "nbColumns = len(dfCredit.columns)\n",
    "print(\"nb of columns\", nbColumns)\n",
    "dfX = dfCredit.iloc[:,:nbColumns-1]\n",
    "dfY = dfCredit.iloc[:,nbColumns-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b</th>\n",
       "      <th>30.83</th>\n",
       "      <th>0</th>\n",
       "      <th>u</th>\n",
       "      <th>g</th>\n",
       "      <th>w</th>\n",
       "      <th>v</th>\n",
       "      <th>1.25</th>\n",
       "      <th>t</th>\n",
       "      <th>t.1</th>\n",
       "      <th>1</th>\n",
       "      <th>f</th>\n",
       "      <th>g.1</th>\n",
       "      <th>202</th>\n",
       "      <th>0.1</th>\n",
       "      <th>+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>3.04</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>43</td>\n",
       "      <td>560</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>24.50</td>\n",
       "      <td>0.500</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>1.50</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>280</td>\n",
       "      <td>824</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>3.75</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.71</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>32.08</td>\n",
       "      <td>4.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>m</td>\n",
       "      <td>v</td>\n",
       "      <td>2.50</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>360</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   b  30.83      0  u  g  w  v  1.25  t t.1  1  f g.1  202  0.1  +\n",
       "0  a  58.67  4.460  u  g  q  h  3.04  t   t  6  f   g   43  560  +\n",
       "1  a  24.50  0.500  u  g  q  h  1.50  t   f  0  f   g  280  824  +\n",
       "2  b  27.83  1.540  u  g  w  v  3.75  t   t  5  t   g  100    3  +\n",
       "3  b  20.17  5.625  u  g  w  v  1.71  t   f  0  f   s  120    0  +\n",
       "4  b  32.08  4.000  u  g  m  v  2.50  t   f  0  t   g  360    0  +"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfCredit.head()\n",
    "#Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "X (687, 15)\n",
      "['a' '24.50' 0.5 'u' 'g' 'q' 'h' 1.5 't' 'f' 0 'f' 'g' '280' 824] <class 'str'>\n",
      "numeric_columns [False, True, True, False, False, False, False, True, False, False, True, False, False, True, True]\n",
      "before NaN remove X_num (687, 6) Y_num (687,)\n",
      "test1 [ 24.5   0.5   1.5   0.  280.  824. ]\n",
      "after NaN remove X_num: (665, 6) Y_num: (665,)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\"\"\"\n",
    "    Vérifie si une chaine correspond à un format numérique (entier ou flotant)\n",
    "\"\"\"\n",
    "def is_num(entry):\n",
    "    _str = str(entry)\n",
    "    #print(\"is_num\", _str)\n",
    "    regex_float = '[+-]?[0-9]+\\.[0-9]+'\n",
    "    regex_int = '[0-9]+'\n",
    "    # Répérer les entiers\n",
    "    if(re.search(regex_int, _str)):  \n",
    "        #print(str, \"Integer number\")  \n",
    "        return True\n",
    "    # Répérer les flotants\n",
    "    elif(re.search(regex_float, _str)):  \n",
    "        #print(str, \"Floating point number\")  \n",
    "        return True\n",
    "    else:  \n",
    "        #print(_str, \"not a number\")  \n",
    "        return False\n",
    "\n",
    "print(is_num('013'))\n",
    "\n",
    "\n",
    "# Conversion de tous les éléments du tableau en float\n",
    "def y_to_num(Y):\n",
    "    #print(\"Y\", Y[0],Y[1] )\n",
    "    Y_num = np.zeros(len(Y));\n",
    "    for idx in range(len(Y)):\n",
    "        #print(\"step1\",idx,Y[idx])\n",
    "        if(Y[idx] == '+'):\n",
    "            #print('set 1')\n",
    "            Y_num[idx] = 1\n",
    "    return Y_num\n",
    "\n",
    "\"\"\"\n",
    "    Vérifie si un ligne(tableau) contient au moins un élément Not-A-Number\n",
    "\"\"\"\n",
    "def has_nan(row):\n",
    "    array_sum = np.sum(row)\n",
    "    return np.isnan(array_sum)\n",
    "\n",
    "# Transformation en array\n",
    "arrayCredit = dfCredit.to_numpy()\n",
    "# Extraction des variables caractéristiques\n",
    "X = (dfCredit.iloc[:,:nbColumns-1]).to_numpy()\n",
    "# Extraction de la varaiable à prédire\n",
    "Y = (dfCredit.iloc[:,nbColumns-1]).to_numpy()\n",
    "print(\"X\", X.shape)\n",
    "#print(arrayCredit, X,Y)\n",
    "\n",
    "# Sélection des colonnes de type numérique ()\n",
    "row1 = X[1,:]\n",
    "print(row1, type(row1[1]))\n",
    "numeric_columns=[]\n",
    "numeric_columns = [is_num(row1[i]  )  for i in range(len(row1))]\n",
    "cat_columns = [not is_num(row1[i]  )  for i in range(len(row1))]\n",
    "\n",
    "\n",
    "    \n",
    "print(\"numeric_columns\", numeric_columns)\n",
    "#selections = np.array([True, False, True])\n",
    "X_num = X[:, numeric_columns]\n",
    "\n",
    "\"\"\"\n",
    "Y_num = np.zeros(len(Y));\n",
    "# Conversion de tous les éléments du tableau en float\n",
    "print(\"Y\", Y[0],Y[1] )\n",
    "lengthY = len(Y)\n",
    "for idx in range(lengthY):\n",
    "    #print(\"step1\",idx,Y[idx])\n",
    "    if(Y[idx] == '+'):\n",
    "        #print('set 1')\n",
    "        Y_num[idx] = 1\n",
    "\"\"\"\n",
    "Y_num = y_to_num(Y)\n",
    "\n",
    "\n",
    "#print(\"y value\",idx_row, Y[idx_row])\n",
    "#print(\"Y_num\", Y_num)\n",
    "\n",
    "\n",
    "# Remplacer les '?' par des nan\n",
    "X_num[X_num == '?'] = np.nan\n",
    "# Forcer le type float\n",
    "X_num = X_num.astype(float)\n",
    "#print(\"X_num\", X_num)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# Suppression des lignes comporanant un nan\n",
    "print( \"before NaN remove X_num\", X_num.shape, \"Y_num\", Y_num.shape) \n",
    "\n",
    "selected_rows = []\n",
    "X_clean = []\n",
    "print(\"test1\", X_num[1,:])\n",
    "fNaN = float('nan')\n",
    "for row in X_num:\n",
    "    selected_rows.append(not has_nan(row))\n",
    "\n",
    "X_num = X_num[selected_rows,:]\n",
    "Y_num = Y_num[selected_rows]\n",
    "\n",
    "MP = 100*np.sum(Y_num == 0)/len(Y)\n",
    "BP = 100*np.sum(Y_num == 1)/len(Y)\n",
    "\n",
    "print(\"after NaN remove X_num:\", X_num.shape, \"Y_num:\", Y_num.shape) \n",
    "\n",
    "# A Enlever\n",
    "#X_num_bk = X_num\n",
    "#Y_num_bk = Y_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(665,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def group_list(list):       \n",
    "    unique, counts = np.unique(list, return_counts=True)\n",
    "    return dict(zip(unique, counts))\n",
    "\n",
    "# Affichage\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Fixing random state for reproducibility\n",
    "print(Y_num.shape)\n",
    "mapY = group_list(Y_num)\n",
    "#print(\"mapY\", mapY)\n",
    "\n",
    "plt.rcdefaults()\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "x_values=[]\n",
    "y_values=[]\n",
    "for val_y in mapY :\n",
    "    val = mapY[val_y]\n",
    "    y_values.append(val)\n",
    "\n",
    "x_values = mapY.keys()\n",
    "y_pos = np.arange(len(x_values))\n",
    "#print(\"y_values\", y_values)\n",
    "error = np.random.rand(len(x_values))\n",
    "\n",
    "ax.barh(y_pos, y_values, xerr=error, align='center')\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(x_values)\n",
    "ax.invert_yaxis()  # labels read top-to-bottom\n",
    "ax.set_xlabel('Nb of entries')\n",
    "ax.set_title('Nb of entries by y value')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(665, 6)\n"
     ]
    }
   ],
   "source": [
    "# Normalisation \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "SC = StandardScaler()\n",
    "SC.fit(X_num)\n",
    "X_norm = SC.transform(X_num)\n",
    "\n",
    "print(X_norm.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix, precision_score, accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\" \n",
    "    Fontion utilitaire d'affichage des résultat d'un algorithme : matrice de confusion, accuracy, precision\n",
    "\"\"\"\n",
    "def log_result(Y_test, Y_pred, algoType, note):\n",
    "    print(\"--- \", algoType, \" ---\" )\n",
    "    m_confusion = confusion_matrix(Y_test, Y_pred )\n",
    "    print(\"Matrice de confusion\", algoType, note)\n",
    "    print(m_confusion)\n",
    "    acc = round(100*accuracy_score(Y_test, Y_pred), 2)\n",
    "    prec = round(100*precision_score(Y_test, Y_pred), 2)\n",
    "    print(algoType, note, ' : Accuracy  ', acc , 'Precision' , prec)\n",
    "    \n",
    "\n",
    "def run_classifiers(X,Y,list_classifiers):\n",
    "    # Estimation par 10 fold cross-validation du critère qu’il vous semble le plus pertinent entre le\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "    for i in list_classifiers:\n",
    "        classifier = list_classifiers[i]\n",
    "        time_before = time.time()\n",
    "        cv_acc = cross_val_score(classifier, X, Y, cv=kf)\n",
    "        #print(\"run_classifiers cv_acc\", cv_acc, X, Y)\n",
    "        time_after = time.time()\n",
    "        # Estimation du temps d’exécution de l’algorithme d’apprentissage (c.f. time.time())\n",
    "        duraction_sec = time_after - time_before\n",
    "        # Estimation de l’accuracy et de l’AUC (Aire sous la courbe ROC) par 10 fold cross-validation (c.f.\n",
    "        #accuracy = np.mean(cv_acc)    \n",
    "        #std = np.std(cv_acc)\n",
    "        cv_precision = cross_val_score(classifier, X, Y, cv=kf, scoring='precision')\n",
    "        cv_auc = cross_val_score(classifier, X, Y, cv=kf, scoring='roc_auc')\n",
    "        #print(X.shape, Y.shape, cv_acc)\n",
    "        print(\" Accuracy for {0} is: {1:.3f} +/- {2:.3f}  duration : {3:.3f} sec\".format(i, np.mean(cv_acc), np.std(cv_acc), duraction_sec))\n",
    "        print(\"Precision for {0} is: {1:.3f} +/- {2:.3f}  duration : {3:.3f} sec\".format(i, np.mean(cv_precision), np.std(cv_precision), duraction_sec))\n",
    "        print(\"   A.U.C. for {0} is: {1:.3f} +/- {2:.3f}  duration : {3:.3f} sec\".format(i, np.mean(cv_auc), np.std(cv_auc), duraction_sec))\n",
    "    print(\"--- run_classifiers end ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy for GNB is: 0.714 +/- 0.058  duration : 0.034 sec\n",
      "Precision for GNB is: 0.842 +/- 0.105  duration : 0.034 sec\n",
      "   A.U.C. for GNB is: 0.793 +/- 0.057  duration : 0.034 sec\n",
      " Accuracy for CART is: 0.695 +/- 0.034  duration : 0.048 sec\n",
      "Precision for CART is: 0.670 +/- 0.079  duration : 0.048 sec\n",
      "   A.U.C. for CART is: 0.703 +/- 0.046  duration : 0.048 sec\n",
      " Accuracy for ID3 is: 0.735 +/- 0.058  duration : 0.047 sec\n",
      "Precision for ID3 is: 0.729 +/- 0.085  duration : 0.047 sec\n",
      "   A.U.C. for ID3 is: 0.745 +/- 0.049  duration : 0.047 sec\n",
      " Accuracy for STRUMP is: 0.744 +/- 0.054  duration : 0.029 sec\n",
      "Precision for STRUMP is: 0.868 +/- 0.061  duration : 0.029 sec\n",
      "   A.U.C. for STRUMP is: 0.723 +/- 0.035  duration : 0.029 sec\n",
      " Accuracy for MLP is: 0.786 +/- 0.058  duration : 11.904 sec\n",
      "Precision for MLP is: 0.823 +/- 0.084  duration : 11.904 sec\n",
      "   A.U.C. for MLP is: 0.844 +/- 0.055  duration : 11.904 sec\n",
      " Accuracy for KNN is: 0.753 +/- 0.041  duration : 0.131 sec\n",
      "Precision for KNN is: 0.793 +/- 0.076  duration : 0.131 sec\n",
      "   A.U.C. for KNN is: 0.816 +/- 0.033  duration : 0.131 sec\n",
      " Accuracy for BC is: 0.765 +/- 0.055  duration : 3.199 sec\n",
      "Precision for BC is: 0.772 +/- 0.071  duration : 3.199 sec\n",
      "   A.U.C. for BC is: 0.827 +/- 0.048  duration : 3.199 sec\n",
      " Accuracy for ADB is: 0.788 +/- 0.053  duration : 2.275 sec\n",
      "Precision for ADB is: 0.789 +/- 0.076  duration : 2.275 sec\n",
      "   A.U.C. for ADB is: 0.848 +/- 0.051  duration : 2.275 sec\n",
      " Accuracy for RF is: 0.779 +/- 0.051  duration : 2.182 sec\n",
      "Precision for RF is: 0.797 +/- 0.088  duration : 2.182 sec\n",
      "   A.U.C. for RF is: 0.842 +/- 0.058  duration : 2.182 sec\n",
      "--- run_classifiers end ---\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import recall_score\n",
    "#Import Gaussian Naive Bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import time\n",
    "\n",
    "\"\"\" Fonction qui applique successivement les 3 algorithmes : \n",
    "        . Arbre de décision\n",
    "        . K plus proches voisins\n",
    "        . Perceptron multi-couches\n",
    "\"\"\"\n",
    "\n",
    "list_classifiers = {\n",
    "  # NaiveBayesSimple\n",
    "     'GNB' : GaussianNB()\n",
    "  # Un arbre CART\n",
    "    ,'CART': DecisionTreeClassifier(criterion = 'gini')\n",
    "  # Un arbre ID3\n",
    "    ,'ID3' : DecisionTreeClassifier(criterion = 'entropy',max_depth=8,splitter='best')\n",
    "  # Decision Stump\n",
    "    ,'STRUMP':  DecisionTreeClassifier(max_depth=1)\n",
    "  # MultilayerPerceptron à deux couches de tailles respectives 20 et 10 par exemple\n",
    "    ,'MLP' : MLPClassifier(  hidden_layer_sizes=(20, 10), alpha=0.001, max_iter=200)\n",
    "  # k-plus-proches-voisins avec k=5 par exemple\n",
    "    ,'KNN' : KNeighborsClassifier(n_neighbors=5)\n",
    "  # Bagging avec 50 classifieurs par exemple\n",
    "    ,'BC' : BaggingClassifier(n_estimators=50)\n",
    "  # AdaBoost avec 50 classifieurs par exemple\n",
    "    ,'ADB' : AdaBoostClassifier(n_estimators=50) \n",
    "  # Random Forest avec 50 classifieurs par exemple\n",
    "    ,'RF'  : RandomForestClassifier(n_estimators=50)\n",
    "}\n",
    "\n",
    "\n",
    "run_classifiers(X_norm, Y_num, list_classifiers)\n",
    "\n",
    "# TODO : comparer les résultats avec ceux de la question précédente\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traitement des données manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat_columns_ids [0, 3, 4, 5, 6, 8, 9, 11, 12]\n",
      "step10 X_cat [['a' 'u' 'g' 'q' 'h' 't' 't' 'f' 'g']\n",
      " ['a' 'u' 'g' 'q' 'h' 't' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'w' 'v' 't' 't' 't' 'g']]\n",
      "step1 X_cat   (687, 9) [[1 2 1 11 4 1 1 0 0]\n",
      " [1 2 1 11 4 1 0 0 0]\n",
      " [2 2 1 13 8 1 1 1 0]]\n",
      "step2 X_num   (687, 6) [['58.67' 4.46 3.04 6 '43' 560]\n",
      " ['24.50' 0.5 1.5 0 '280' 824]\n",
      " ['27.83' 1.54 3.75 5 '100' 3]]\n",
      "step3 X_num   (687, 6) [[ 58.67   4.46   3.04   6.    43.   560.  ]\n",
      " [ 24.5    0.5    1.5    0.   280.   824.  ]\n",
      " [ 27.83   1.54   3.75   5.   100.     3.  ]]\n",
      "X_num_norm (687, 6) [[ 2.30690858 -0.06337714  0.24237488  0.73962742 -0.81775732 -0.0883501 ]\n",
      " [-0.59647927 -0.85885021 -0.21731315 -0.49318464  0.55688632 -0.03774986]\n",
      " [-0.31353278 -0.64993809  0.45430897  0.53415874 -0.48714683 -0.19510894]]\n",
      "X_cat (687, 9) [[1 2 1 11 4 1 1 0 0]]\n",
      "X_cat_bin (687, 40) [[1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      "  0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "cat_columns_ids0 = [0,3,4,5,6,8,9,11,12]\n",
    "cat_columns_ids = []\n",
    "num_columns_ids = []\n",
    "for idx in range(len(cat_columns)):\n",
    "    if(cat_columns[idx]):\n",
    "        cat_columns_ids.append(idx)\n",
    "    else:\n",
    "        num_columns_ids.append(idx)\n",
    "\n",
    "# Pour les variables catégorielles\n",
    "print(\"cat_columns_ids\", cat_columns_ids)\n",
    "X_cat = np.copy(X[:, cat_columns_ids])\n",
    "print(\"step10 X_cat\", X_cat[0:3,:]  )\n",
    "for col_id in range(len(cat_columns_ids)):\n",
    "    unique_val, val_idx = np.unique(X_cat[:, col_id], return_inverse=True)\n",
    "    X_cat[:, col_id] = val_idx\n",
    "imp_cat = SimpleImputer(missing_values=0, strategy='most_frequent')\n",
    " #imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "\n",
    "X_cat[:, range(5)] = imp_cat.fit_transform(X_cat[:, range(5)])\n",
    "\n",
    "print(\"step1 X_cat  \", X_cat.shape, X_cat[0:3,:] )\n",
    "\n",
    "\n",
    "X_num = np.copy(X[:, num_columns_ids])\n",
    "\n",
    "print(\"step2 X_num  \", X_num.shape, X_num[0:3,:] )\n",
    "# Pour les variables numériques\n",
    "X_num[X_num == '?'] = np.nan\n",
    "X_num = X_num.astype(float)\n",
    "imp_num = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "X_num = imp_num.fit_transform(X_num)\n",
    "\n",
    "print(\"step3 X_num  \", X_num.shape, X_num[0:3,:] )\n",
    "\n",
    "# Normalisation des données numérique obtenues\n",
    "SC = StandardScaler()\n",
    "SC.fit(X_num)\n",
    "X_num_norm = SC.transform(X_num)\n",
    "print(\"X_num_norm\", X_num_norm.shape, X_num_norm[0:3,:])\n",
    "\n",
    "\n",
    "\n",
    "# Conversion des variables  en binaire\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "X_cat_bin = OneHotEncoder().fit_transform(X_cat).toarray()\n",
    "print(\"X_cat\", X_cat.shape, X_cat[0:1,:]   )\n",
    "print(\"X_cat_bin\", X_cat_bin.shape, X_cat_bin[0:1,:])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_num [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "X_transformed (687, 46) (687,)\n",
      " Accuracy for GNB is: 0.712 +/- 0.060  duration : 0.034 sec\n",
      "Precision for GNB is: 0.878 +/- 0.102  duration : 0.034 sec\n",
      "   A.U.C. for GNB is: 0.881 +/- 0.045  duration : 0.034 sec\n",
      " Accuracy for CART is: 0.818 +/- 0.039  duration : 0.091 sec\n",
      "Precision for CART is: 0.770 +/- 0.058  duration : 0.091 sec\n",
      "   A.U.C. for CART is: 0.803 +/- 0.038  duration : 0.091 sec\n",
      " Accuracy for ID3 is: 0.834 +/- 0.035  duration : 0.102 sec\n",
      "Precision for ID3 is: 0.790 +/- 0.058  duration : 0.102 sec\n",
      "   A.U.C. for ID3 is: 0.836 +/- 0.046  duration : 0.102 sec\n",
      " Accuracy for STRUMP is: 0.856 +/- 0.051  duration : 0.038 sec\n",
      "Precision for STRUMP is: 0.782 +/- 0.079  duration : 0.038 sec\n",
      "   A.U.C. for STRUMP is: 0.865 +/- 0.050  duration : 0.038 sec\n",
      " Accuracy for MLP is: 0.870 +/- 0.031  duration : 15.168 sec\n",
      "Precision for MLP is: 0.829 +/- 0.076  duration : 15.168 sec\n",
      "   A.U.C. for MLP is: 0.924 +/- 0.033  duration : 15.168 sec\n",
      " Accuracy for KNN is: 0.837 +/- 0.042  duration : 0.359 sec\n",
      "Precision for KNN is: 0.841 +/- 0.089  duration : 0.359 sec\n",
      "   A.U.C. for KNN is: 0.899 +/- 0.045  duration : 0.359 sec\n",
      " Accuracy for BC is: 0.860 +/- 0.033  duration : 4.390 sec\n",
      "Precision for BC is: 0.843 +/- 0.079  duration : 4.390 sec\n",
      "   A.U.C. for BC is: 0.928 +/- 0.034  duration : 4.390 sec\n",
      " Accuracy for ADB is: 0.849 +/- 0.045  duration : 2.320 sec\n",
      "Precision for ADB is: 0.819 +/- 0.094  duration : 2.320 sec\n",
      "   A.U.C. for ADB is: 0.911 +/- 0.043  duration : 2.320 sec\n",
      " Accuracy for RF is: 0.872 +/- 0.034  duration : 2.261 sec\n",
      "Precision for RF is: 0.850 +/- 0.076  duration : 2.261 sec\n",
      "   A.U.C. for RF is: 0.933 +/- 0.033  duration : 2.261 sec\n",
      "--- run_classifiers end ---\n"
     ]
    }
   ],
   "source": [
    "# Concaténation finale\n",
    "X_transformed = np.concatenate((X_num_norm, X_cat_bin), axis=1)\n",
    "\n",
    "\n",
    "Y_num = y_to_num(Y)\n",
    "print(\"Y_num\", Y_num[0:20])\n",
    "\n",
    "# Application des classifieurs\n",
    "#print(\"X_Array_transformed\", X_Array_transformed.shape, X_Array_transformed[0:1,:], Y_num.shape)\n",
    "print(\"X_transformed\", X_transformed.shape, Y_num.shape)\n",
    "\n",
    "\n",
    "run_classifiers(X_transformed, Y_num, list_classifiers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST  (A ENLEVER)\n",
    "if(1==0):\n",
    "    print(\"step000\")\n",
    "\n",
    "    Y_num2 = Y.copy()\n",
    "    # Conversion des éléments du tableau en float\n",
    "    print(\"Y\", Y[0:20])\n",
    "    Y_num2[Y_num2=='+']=int(1) #float(1.0)\n",
    "    Y_num2[Y_num2=='-']=int(0) #float(0.0)\n",
    "\n",
    "    Y_num2[1==1] = Y_num2.astype('int')\n",
    "\n",
    "    for i,y in enumerate(Y_num2):\n",
    "        Y_num2[i]=y.astype('int')\n",
    "\n",
    "    print(\"Y_num2\", Y_num2)\n",
    "\n",
    "    KNN = KNeighborsClassifier(n_neighbors=5)\n",
    "    KNN.fit(X_num, Y_num2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
